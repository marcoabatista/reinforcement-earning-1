{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade Prática II - Treinamento e Validação de Modelos de RL\n",
    "\n",
    "**Aluno:** Marco Antonio Batista\n",
    "\n",
    "**Disciplina:** Reinforcement Learning - Turma II\n",
    "\n",
    "**Data:** 21/08/2021\n",
    "\n",
    "\n",
    "\n",
    "Neste trabalho vamos aplicar `Gym`, `Stable-Baselines3` e `RL Baselines Zoo` para lidar com o treinamento e validação de problemas de aprendizado por reforço. Sua tarefa é:\n",
    "\n",
    "1. Selecionar um cenário da biblioteca `Gym` de sua preferência, desde que este cenário também seja contemplado pelos modelos disponibilizados na `rl baselines zoo`;\n",
    "2. Selecionar três algoritmos das biblioteca `Stable-baselines3` para resolver esse problema. Pesquise na documentação da biblioteca quais são os algoritmos mais adequados para o ambiente escolhido e justifique a sua escolha. \n",
    "3. Realize o treinamento de cada um dos três modelos ---você pode ajustar os parâmetros do modelos, se achar necessário--- e salve os modelos em disco.\n",
    "4. De posse dos modelos treinados e salvos, carregue-os e avalie-os por 10 episódios. Apresente os resultados médios e gere a curva de recompensa acumulada disponibilizada pelo `TensorBoard`.\n",
    "5. Compare os resultados dos modelos treinados com os resultados obtidos por modelo(s) existentes no `RL Baselines Zoo` para o cenário escolhido.\n",
    "6. Gere um vídeo do melhor modelo que você treinou e do modelo escolhido na `RL Baselines Zoo`. Verifique a documentação de cada biblioteca sobre a criação do vídeo e visualização em Notebooks.\n",
    "\n",
    "\n",
    "\n",
    "* **Data de entrega:** 04/09/2021\n",
    "* **Local de envio:** AVA.\n",
    "* **Tipo de documento:** Notebook (`.ipynb`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "\n",
    "import time\n",
    "\n",
    "# Create environment\n",
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 22:44:06.948345: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 22:44:06.948379: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./lunar_tensorboard/train_dqn/DQN_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -195     |\n",
      "|    exploration rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 322      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 419      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -205     |\n",
      "|    exploration rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 816      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -252     |\n",
      "|    exploration rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 1176     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.5     |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 1496     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.8     |\n",
      "|    ep_rew_mean      | -199     |\n",
      "|    exploration rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1135     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 1857     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.6     |\n",
      "|    ep_rew_mean      | -179     |\n",
      "|    exploration rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1285     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 2223     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.8     |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1413     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 2542     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.2     |\n",
      "|    ep_rew_mean      | -177     |\n",
      "|    exploration rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1549     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 2917     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.8     |\n",
      "|    ep_rew_mean      | -189     |\n",
      "|    exploration rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1680     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 3304     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.5     |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1793     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 3660     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.8     |\n",
      "|    ep_rew_mean      | -192     |\n",
      "|    exploration rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1904     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 4040     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.9     |\n",
      "|    ep_rew_mean      | -189     |\n",
      "|    exploration rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1982     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 4314     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90       |\n",
      "|    ep_rew_mean      | -186     |\n",
      "|    exploration rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 2078     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 4678     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.4     |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 2174     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 5061     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 2266     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 5452     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 2349     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 5818     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.3     |\n",
      "|    ep_rew_mean      | -181     |\n",
      "|    exploration rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 2412     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 6141     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.8     |\n",
      "|    ep_rew_mean      | -179     |\n",
      "|    exploration rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 2469     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 6465     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.9     |\n",
      "|    ep_rew_mean      | -179     |\n",
      "|    exploration rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 2520     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 6831     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.6     |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 2560     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 7167     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89       |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 2602     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.4     |\n",
      "|    ep_rew_mean      | -177     |\n",
      "|    exploration rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 2661     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 7871     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90       |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 2709     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 8280     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.5     |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 2763     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 8690     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | -174     |\n",
      "|    exploration rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 9092     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.5     |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 2833     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 9467     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.1     |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration rate | 0.0757   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 9730     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.2     |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 10098    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89       |\n",
      "|    ep_rew_mean      | -164     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 2921     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 10393    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88.4     |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 10701    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88.7     |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 11088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89       |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 11446    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88.8     |\n",
      "|    ep_rew_mean      | -180     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 3036     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 11793    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total timesteps  | 13060    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total timesteps  | 13358    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.9     |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 2789     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total timesteps  | 13726    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 14172    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 2833     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 14563    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -174     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 14989    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 2863     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 15331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 2882     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 15731    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 16108    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -178     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 16468    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 16809    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 2934     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 17167    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 17596    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 18010    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 2975     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 18339    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 2982     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 18710    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -185     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 19036    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 3009     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 19520    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -187     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 3018     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 19913    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 20304    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -191     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 3042     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 20752    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -189     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 3045     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total timesteps  | 21157    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -187     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 21531    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -185     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 3077     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 21966    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -177     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 22302    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.5     |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 3112     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 22715    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -181     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 3131     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 23143    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -185     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 3148     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 23518    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 3160     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 23891    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 3168     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 24258    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.3     |\n",
      "|    ep_rew_mean      | -181     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 3174     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 24621    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.7     |\n",
      "|    ep_rew_mean      | -190     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 3187     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 25000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.9     |\n",
      "|    ep_rew_mean      | -188     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 3198     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 25422    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.3     |\n",
      "|    ep_rew_mean      | -186     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 3203     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 25739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.1     |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 3195     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 26175    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 26551    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -186     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 3206     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 26922    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -180     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 3211     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 27295    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.1     |\n",
      "|    ep_rew_mean      | -174     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 3221     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 27619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.9     |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 3229     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 27928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.1     |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 3237     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 28324    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.3     |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 3242     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 28671    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.4     |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 3256     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 29163    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 3263     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 29510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.7     |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 29876    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.3     |\n",
      "|    ep_rew_mean      | -168     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 30185    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.3     |\n",
      "|    ep_rew_mean      | -168     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 3281     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 30587    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.1     |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 3293     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 30937    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 3113     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 32230    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -168     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 3118     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 32631    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 33000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -170     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 3137     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 33420    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 3148     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 33745    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -168     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 3156     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 34127    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -168     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 3167     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 34475    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total timesteps  | 34790    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 3185     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 35138    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -164     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 3197     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 35497    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 3206     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 35882    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 3216     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 36253    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -164     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 3226     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 36666    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 3235     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 37035    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 3244     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 37372    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -166     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 3253     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 37702    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 3260     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 38033    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 3272     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 38457    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -164     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 3282     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 38808    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 3292     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 39108    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 39466    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 39829    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 3321     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 40199    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 3330     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 40536    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 3340     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 40922    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.5     |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 3352     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 41377    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91       |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 3362     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 41728    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 3370     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 42088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.1     |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 3379     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 42433    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90       |\n",
      "|    ep_rew_mean      | -160     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 3387     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 42745    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.7     |\n",
      "|    ep_rew_mean      | -162     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 3395     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 43092    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.2     |\n",
      "|    ep_rew_mean      | -160     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 3402     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 43492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.5     |\n",
      "|    ep_rew_mean      | -158     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 3410     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 43839    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91       |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 3420     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 44233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.7     |\n",
      "|    ep_rew_mean      | -158     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 3428     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total timesteps  | 44568    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 3437     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 44976    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.4     |\n",
      "|    ep_rew_mean      | -157     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 3446     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 45395    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.6     |\n",
      "|    ep_rew_mean      | -158     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 3454     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 45724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.2     |\n",
      "|    ep_rew_mean      | -159     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 3460     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 46056    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.8     |\n",
      "|    ep_rew_mean      | -155     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 3465     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 46456    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.1     |\n",
      "|    ep_rew_mean      | -154     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 3471     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 46815    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.9     |\n",
      "|    ep_rew_mean      | -158     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 3477     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 47225    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.4     |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 3484     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 47601    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91       |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 3489     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 47913    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.7     |\n",
      "|    ep_rew_mean      | -161     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 3494     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 48277    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.5     |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 3499     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 48620    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.2     |\n",
      "|    ep_rew_mean      | -160     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 3505     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total timesteps  | 48948    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.5     |\n",
      "|    ep_rew_mean      | -162     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 3509     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total timesteps  | 49354    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.4     |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 3515     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total timesteps  | 49773    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.8     |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 3505     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total timesteps  | 50101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 25       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.2     |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 3462     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total timesteps  | 50402    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.87     |\n",
      "|    n_updates        | 100      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.7     |\n",
      "|    ep_rew_mean      | -202     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 3408     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total timesteps  | 50799    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 199      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.2     |\n",
      "|    ep_rew_mean      | -219     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 3351     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total timesteps  | 51212    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53     |\n",
      "|    n_updates        | 302      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.1     |\n",
      "|    ep_rew_mean      | -234     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 3270     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total timesteps  | 51643    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 410      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.3     |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total timesteps  | 52073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 518      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.5     |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 3150     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total timesteps  | 52442    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.718    |\n",
      "|    n_updates        | 610      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.5     |\n",
      "|    ep_rew_mean      | -292     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 3082     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total timesteps  | 53142    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.38     |\n",
      "|    n_updates        | 785      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total timesteps  | 53833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.935    |\n",
      "|    n_updates        | 958      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -306     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 2882     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total timesteps  | 55099    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.9      |\n",
      "|    n_updates        | 1274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | -312     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total timesteps  | 56208    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.864    |\n",
      "|    n_updates        | 1551     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | -312     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 2649     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total timesteps  | 57595    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.921    |\n",
      "|    n_updates        | 1898     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | -311     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 2521     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total timesteps  | 58904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.625    |\n",
      "|    n_updates        | 2225     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | -315     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 2418     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total timesteps  | 60305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 2576     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | -318     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 2228     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total timesteps  | 62343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.908    |\n",
      "|    n_updates        | 3085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 175      |\n",
      "|    ep_rew_mean      | -322     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 2143     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total timesteps  | 63985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 3496     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 188      |\n",
      "|    ep_rew_mean      | -322     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 2047     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total timesteps  | 65613    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.99     |\n",
      "|    n_updates        | 3903     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | -321     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 1989     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total timesteps  | 67059    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.593    |\n",
      "|    n_updates        | 4264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 208      |\n",
      "|    ep_rew_mean      | -324     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 1955     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total timesteps  | 68369    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.481    |\n",
      "|    n_updates        | 4592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 214      |\n",
      "|    ep_rew_mean      | -325     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 1932     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total timesteps  | 69277    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 4819     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 219      |\n",
      "|    ep_rew_mean      | -329     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 1912     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total timesteps  | 70173    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.75     |\n",
      "|    n_updates        | 5043     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 239      |\n",
      "|    ep_rew_mean      | -329     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 1748     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total timesteps  | 72498    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 5624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 243      |\n",
      "|    ep_rew_mean      | -336     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 1736     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total timesteps  | 73271    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 5817     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 246      |\n",
      "|    ep_rew_mean      | -344     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 1729     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total timesteps  | 73926    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 5981     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -345     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 1716     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total timesteps  | 74788    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 6196     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 256      |\n",
      "|    ep_rew_mean      | -346     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 1703     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total timesteps  | 75709    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.957    |\n",
      "|    n_updates        | 6427     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 273      |\n",
      "|    ep_rew_mean      | -342     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 1640     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total timesteps  | 77739    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 6934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -320     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 1517     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total timesteps  | 80987    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 7746     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -311     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 1510     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total timesteps  | 81944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.874    |\n",
      "|    n_updates        | 7985     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 336      |\n",
      "|    ep_rew_mean      | -293     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 1436     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total timesteps  | 85217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.705    |\n",
      "|    n_updates        | 8804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 365      |\n",
      "|    ep_rew_mean      | -268     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 1359     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total timesteps  | 88560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 9639     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 397      |\n",
      "|    ep_rew_mean      | -251     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 1298     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total timesteps  | 92116    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.928    |\n",
      "|    n_updates        | 10528    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 430      |\n",
      "|    ep_rew_mean      | -232     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 1221     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total timesteps  | 96116    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.97     |\n",
      "|    n_updates        | 11528    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 458      |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 1181     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total timesteps  | 99588    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 12396    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the agent\n",
    "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=\"./lunar_tensorboard/train_dqn/\")\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=100000)\n",
    "# Save the agent\n",
    "model.save(\"lunar_dqn\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./lunar_tensorboard/train_ppo/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 92.2     |\n",
      "|    ep_rew_mean     | -187     |\n",
      "| time/              |          |\n",
      "|    fps             | 1654     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.4        |\n",
      "|    ep_rew_mean          | -189        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1202        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010804996 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.00098    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 821         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.8        |\n",
      "|    ep_rew_mean          | -183        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1118        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010057006 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.00679    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 597         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1056        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010638263 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 839         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1056        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009682015 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.0211     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    value_loss           | 530         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | -169        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1051        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011550146 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.000729   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 735         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | -153        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1041        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013970417 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.0147     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    value_loss           | 605         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | -137        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1033        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009097258 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.000477    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    value_loss           | 328         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | -133        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1018        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007873461 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -0.00274    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 362         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 999         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009951003 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -7.71e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 693         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 136         |\n",
      "|    ep_rew_mean          | -133        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 969         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009576779 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -0.00409    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 293         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    value_loss           | 617         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | -120        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 909         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007878045 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.0568      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 533         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    value_loss           | 584         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 157         |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 868         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003758311 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.0737      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 842         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007461721 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.0377      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 457         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 173        |\n",
      "|    ep_rew_mean          | -106       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 811        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00337638 |\n",
      "|    clip_fraction        | 0.00244    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | -0.501     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 62.3       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.00202   |\n",
      "|    value_loss           | 247        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008843059 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 203          |\n",
      "|    ep_rew_mean          | -102         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068479255 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 215          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 212          |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050352733 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 257          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 231         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007160809 |\n",
      "|    clip_fraction        | 0.00918     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | -101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009468054 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 265        |\n",
      "|    ep_rew_mean          | -103       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 685        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00607077 |\n",
      "|    clip_fraction        | 0.0353     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | -0.181     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 82.5       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.00535   |\n",
      "|    value_loss           | 198        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 275          |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056782756 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.8         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 294         |\n",
      "|    ep_rew_mean          | -99.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008993436 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 308          |\n",
      "|    ep_rew_mean          | -88.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 660          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042503243 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 321         |\n",
      "|    ep_rew_mean          | -85.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008927853 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 338          |\n",
      "|    ep_rew_mean          | -83          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069243237 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | -79.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010627395 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 367          |\n",
      "|    ep_rew_mean          | -73.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071962425 |\n",
      "|    clip_fraction        | 0.0736       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 67.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 384         |\n",
      "|    ep_rew_mean          | -66.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011176149 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -59.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066431887 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 417         |\n",
      "|    ep_rew_mean          | -56.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 619         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005277424 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.905      |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 433         |\n",
      "|    ep_rew_mean          | -52.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011555115 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 448         |\n",
      "|    ep_rew_mean          | -46.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008658133 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 469          |\n",
      "|    ep_rew_mean          | -39.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 595          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039584967 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.956       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.61         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 17.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 482         |\n",
      "|    ep_rew_mean          | -36.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011167254 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 489         |\n",
      "|    ep_rew_mean          | -32.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013173198 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.946      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 88.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 501         |\n",
      "|    ep_rew_mean          | -26.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 577         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006754574 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 518         |\n",
      "|    ep_rew_mean          | -22.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004033209 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 535         |\n",
      "|    ep_rew_mean          | -15.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006398624 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 9.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 551         |\n",
      "|    ep_rew_mean          | -7.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004935196 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 569         |\n",
      "|    ep_rew_mean          | 4.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813117 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 570         |\n",
      "|    ep_rew_mean          | 8.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 579         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010032514 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.818      |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | 19.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 581          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031115427 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.94        |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 585         |\n",
      "|    ep_rew_mean          | 33.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 581         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008188317 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 592       |\n",
      "|    ep_rew_mean          | 46        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 584       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0084526 |\n",
      "|    clip_fraction        | 0.0496    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.826    |\n",
      "|    explained_variance   | 0.374     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 140       |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | -0.00299  |\n",
      "|    value_loss           | 194       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 64.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060803043 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.835       |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 235          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 596          |\n",
      "|    ep_rew_mean          | 85.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 582          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026152432 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.772       |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.4         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 578          |\n",
      "|    ep_rew_mean          | 101          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030937635 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.814       |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 560          |\n",
      "|    ep_rew_mean          | 119          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043404168 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.756       |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 178          |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the agent\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=\"./lunar_tensorboard/train_ppo/\")\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=100000)\n",
    "# Save the agent\n",
    "model.save(\"lunar_ppo\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./lunar_tensorboard/train_a2c/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.6     |\n",
      "|    ep_rew_mean        | -308     |\n",
      "| time/                 |          |\n",
      "|    fps                | 650      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.0046   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -15.8    |\n",
      "|    value_loss         | 180      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | -332     |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.42    |\n",
      "|    explained_variance | 0.051    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    value_loss         | 591      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | -413     |\n",
      "| time/                 |          |\n",
      "|    fps                | 694      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.662   |\n",
      "|    explained_variance | 0.0195   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -20.2    |\n",
      "|    value_loss         | 397      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 106       |\n",
      "|    ep_rew_mean        | -467      |\n",
      "| time/                 |           |\n",
      "|    fps                | 704       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.468    |\n",
      "|    explained_variance | -0.000153 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -20.9     |\n",
      "|    value_loss         | 575       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 107       |\n",
      "|    ep_rew_mean        | -464      |\n",
      "| time/                 |           |\n",
      "|    fps                | 703       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.04     |\n",
      "|    explained_variance | -0.000852 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -1.43     |\n",
      "|    value_loss         | 5.02      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 110       |\n",
      "|    ep_rew_mean        | -495      |\n",
      "| time/                 |           |\n",
      "|    fps                | 668       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.972    |\n",
      "|    explained_variance | -3.39e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -10.8     |\n",
      "|    value_loss         | 57.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 107       |\n",
      "|    ep_rew_mean        | -500      |\n",
      "| time/                 |           |\n",
      "|    fps                | 680       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.787    |\n",
      "|    explained_variance | -0.000254 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -11       |\n",
      "|    value_loss         | 111       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 108      |\n",
      "|    ep_rew_mean        | -479     |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.918   |\n",
      "|    explained_variance | -0.00062 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.302    |\n",
      "|    value_loss         | 8.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | -454     |\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.555   |\n",
      "|    explained_variance | 0.00546  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -20      |\n",
      "|    value_loss         | 421      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | -443     |\n",
      "| time/                 |          |\n",
      "|    fps                | 652      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | -6.9e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 4.7      |\n",
      "|    value_loss         | 47       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 120      |\n",
      "|    ep_rew_mean        | -433     |\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.812   |\n",
      "|    explained_variance | 0.000172 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.7      |\n",
      "|    value_loss         | 4.86     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 125       |\n",
      "|    ep_rew_mean        | -423      |\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.945    |\n",
      "|    explained_variance | -3.28e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -1.97     |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 128       |\n",
      "|    ep_rew_mean        | -411      |\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.88     |\n",
      "|    explained_variance | -3.89e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -9.56     |\n",
      "|    value_loss         | 168       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 133       |\n",
      "|    ep_rew_mean        | -405      |\n",
      "| time/                 |           |\n",
      "|    fps                | 643       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.679    |\n",
      "|    explained_variance | -0.000465 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.44      |\n",
      "|    value_loss         | 48.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 132      |\n",
      "|    ep_rew_mean        | -392     |\n",
      "| time/                 |          |\n",
      "|    fps                | 626      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.31    |\n",
      "|    explained_variance | 0.0051   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 32.6     |\n",
      "|    value_loss         | 587      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 132      |\n",
      "|    ep_rew_mean        | -392     |\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | -0.16    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.674    |\n",
      "|    value_loss         | 0.465    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 150       |\n",
      "|    ep_rew_mean        | -380      |\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.696    |\n",
      "|    explained_variance | -0.000376 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 21        |\n",
      "|    value_loss         | 404       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 152      |\n",
      "|    ep_rew_mean        | -367     |\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.84    |\n",
      "|    explained_variance | -0.00433 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -3.4     |\n",
      "|    value_loss         | 25.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 155      |\n",
      "|    ep_rew_mean        | -354     |\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.002    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 4.82     |\n",
      "|    value_loss         | 15.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 157      |\n",
      "|    ep_rew_mean        | -342     |\n",
      "| time/                 |          |\n",
      "|    fps                | 601      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.546   |\n",
      "|    explained_variance | 0.152    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -1.56    |\n",
      "|    value_loss         | 18.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 158      |\n",
      "|    ep_rew_mean        | -333     |\n",
      "| time/                 |          |\n",
      "|    fps                | 609      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.778   |\n",
      "|    explained_variance | -0.0169  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -3.13    |\n",
      "|    value_loss         | 29       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 162      |\n",
      "|    ep_rew_mean        | -323     |\n",
      "| time/                 |          |\n",
      "|    fps                | 616      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.633   |\n",
      "|    explained_variance | -1.62    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -41.4    |\n",
      "|    value_loss         | 4.19e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 162      |\n",
      "|    ep_rew_mean        | -319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 621      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.372   |\n",
      "|    explained_variance | -1.71    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.31     |\n",
      "|    value_loss         | 7.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 164      |\n",
      "|    ep_rew_mean        | -312     |\n",
      "| time/                 |          |\n",
      "|    fps                | 623      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.875   |\n",
      "|    explained_variance | -0.00784 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    value_loss         | 5.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 165      |\n",
      "|    ep_rew_mean        | -309     |\n",
      "| time/                 |          |\n",
      "|    fps                | 627      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.346   |\n",
      "|    explained_variance | -0.0059  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    value_loss         | 6.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 168      |\n",
      "|    ep_rew_mean        | -306     |\n",
      "| time/                 |          |\n",
      "|    fps                | 630      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.722   |\n",
      "|    explained_variance | -0.0102  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 3.92     |\n",
      "|    value_loss         | 36.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 169      |\n",
      "|    ep_rew_mean        | -303     |\n",
      "| time/                 |          |\n",
      "|    fps                | 634      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.466   |\n",
      "|    explained_variance | -0.00811 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    value_loss         | 63.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 170      |\n",
      "|    ep_rew_mean        | -298     |\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.637   |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.737    |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 170      |\n",
      "|    ep_rew_mean        | -292     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | 0.0217   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -1.27    |\n",
      "|    value_loss         | 40.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 172      |\n",
      "|    ep_rew_mean        | -291     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.806   |\n",
      "|    explained_variance | -0.00746 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.401    |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | -289     |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.516   |\n",
      "|    explained_variance | 0.00138  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.727    |\n",
      "|    value_loss         | 4.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | -284     |\n",
      "| time/                 |          |\n",
      "|    fps                | 652      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | 0.0964   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.441   |\n",
      "|    value_loss         | 0.813    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | -281     |\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.572   |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.946    |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | -277     |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.642   |\n",
      "|    explained_variance | 0.659    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -1.57    |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 176      |\n",
      "|    ep_rew_mean        | -275     |\n",
      "| time/                 |          |\n",
      "|    fps                | 665      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.349   |\n",
      "|    explained_variance | 0.0346   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -2.82    |\n",
      "|    value_loss         | 5.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 178       |\n",
      "|    ep_rew_mean        | -274      |\n",
      "| time/                 |           |\n",
      "|    fps                | 668       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.635    |\n",
      "|    explained_variance | -0.000254 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 5.76      |\n",
      "|    value_loss         | 145       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.646   |\n",
      "|    explained_variance | -2.25    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 3.61     |\n",
      "|    value_loss         | 31.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -262     |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0916  |\n",
      "|    explained_variance | 0.314    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.0255   |\n",
      "|    value_loss         | 8.14     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 186       |\n",
      "|    ep_rew_mean        | -259      |\n",
      "| time/                 |           |\n",
      "|    fps                | 675       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.585    |\n",
      "|    explained_variance | -0.000334 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 8.05      |\n",
      "|    value_loss         | 371       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 188      |\n",
      "|    ep_rew_mean        | -248     |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.216   |\n",
      "|    explained_variance | 0.86     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.153    |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 190      |\n",
      "|    ep_rew_mean        | -229     |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.682   |\n",
      "|    explained_variance | -2.44    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -2.1     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 191      |\n",
      "|    ep_rew_mean        | -220     |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.226   |\n",
      "|    explained_variance | -8.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -10      |\n",
      "|    value_loss         | 168      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 196      |\n",
      "|    ep_rew_mean        | -210     |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | -0.257   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -1.37    |\n",
      "|    value_loss         | 4.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 196      |\n",
      "|    ep_rew_mean        | -210     |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.696   |\n",
      "|    explained_variance | -0.593   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.0508   |\n",
      "|    value_loss         | 0.0395   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 204      |\n",
      "|    ep_rew_mean        | -199     |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.609   |\n",
      "|    explained_variance | 0.000677 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.612    |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 205      |\n",
      "|    ep_rew_mean        | -190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | -0.392   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    value_loss         | 6.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 208      |\n",
      "|    ep_rew_mean        | -185     |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.754   |\n",
      "|    explained_variance | -27.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -5.66    |\n",
      "|    value_loss         | 112      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 209      |\n",
      "|    ep_rew_mean        | -180     |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.00163  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.00253 |\n",
      "|    value_loss         | 0.000296 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 213      |\n",
      "|    ep_rew_mean        | -166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.637   |\n",
      "|    explained_variance | 0.64     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.744   |\n",
      "|    value_loss         | 5.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 217      |\n",
      "|    ep_rew_mean        | -152     |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.548   |\n",
      "|    explained_variance | 0.596    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.0745   |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 219      |\n",
      "|    ep_rew_mean        | -140     |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.536   |\n",
      "|    explained_variance | -2.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -5.91    |\n",
      "|    value_loss         | 42.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 220      |\n",
      "|    ep_rew_mean        | -138     |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.699   |\n",
      "|    explained_variance | 0.323    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -3.62    |\n",
      "|    value_loss         | 26.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 226      |\n",
      "|    ep_rew_mean        | -132     |\n",
      "| time/                 |          |\n",
      "|    fps                | 668      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.409   |\n",
      "|    explained_variance | -1.71    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 3.29     |\n",
      "|    value_loss         | 13.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 228      |\n",
      "|    ep_rew_mean        | -129     |\n",
      "| time/                 |          |\n",
      "|    fps                | 667      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.718   |\n",
      "|    explained_variance | 0.083    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 2.03     |\n",
      "|    value_loss         | 16.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 229      |\n",
      "|    ep_rew_mean        | -128     |\n",
      "| time/                 |          |\n",
      "|    fps                | 667      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.674   |\n",
      "|    explained_variance | -0.96    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    value_loss         | 632      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 231      |\n",
      "|    ep_rew_mean        | -124     |\n",
      "| time/                 |          |\n",
      "|    fps                | 668      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.479   |\n",
      "|    explained_variance | 0.598    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    value_loss         | 34.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 234      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.452   |\n",
      "|    explained_variance | -0.195   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 3.56     |\n",
      "|    value_loss         | 66.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 236      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 666      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.413   |\n",
      "|    explained_variance | -0.115   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 2.82     |\n",
      "|    value_loss         | 7.07e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 238      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.441   |\n",
      "|    explained_variance | 0.0801   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -3       |\n",
      "|    value_loss         | 30.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 240      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.573   |\n",
      "|    explained_variance | -0.00944 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    value_loss         | 5.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.213   |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.306   |\n",
      "|    value_loss         | 0.677    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 243      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 662      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.631   |\n",
      "|    explained_variance | -0.0142  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.717   |\n",
      "|    value_loss         | 7.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 243      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.17    |\n",
      "|    explained_variance | 0.064    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.0299   |\n",
      "|    value_loss         | 0.945    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 247      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00166 |\n",
      "|    explained_variance | -0.0743  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.000458 |\n",
      "|    value_loss         | 7.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 240      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.426   |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 5.82     |\n",
      "|    value_loss         | 53.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 243      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.611   |\n",
      "|    explained_variance | -0.252   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0.00532  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -3.52    |\n",
      "|    value_loss         | 53.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 244      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.378   |\n",
      "|    explained_variance | 0.677    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.94     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 244      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.144    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.046   |\n",
      "|    value_loss         | 0.00891  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 248      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.471   |\n",
      "|    explained_variance | -0.0179  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -2.55    |\n",
      "|    value_loss         | 55.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 248       |\n",
      "|    ep_rew_mean        | -110      |\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.554    |\n",
      "|    explained_variance | -6.14e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 7.85      |\n",
      "|    value_loss         | 150       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 249      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 649      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.391   |\n",
      "|    explained_variance | 0.00732  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -1.94    |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 251      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 646      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.642   |\n",
      "|    explained_variance | -0.0513  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 2.49     |\n",
      "|    value_loss         | 28.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 253      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 646      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.584   |\n",
      "|    explained_variance | 0.962    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 255      |\n",
      "|    ep_rew_mean        | -95.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.489   |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 3.19     |\n",
      "|    value_loss         | 83.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 254      |\n",
      "|    ep_rew_mean        | -92.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.387   |\n",
      "|    explained_variance | -0.0247  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 4.42     |\n",
      "|    value_loss         | 49.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 255       |\n",
      "|    ep_rew_mean        | -87.6     |\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0893   |\n",
      "|    explained_variance | -0.00491  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -6.57e-06 |\n",
      "|    value_loss         | 2.18e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -86.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.573   |\n",
      "|    explained_variance | -0.121   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -5.57    |\n",
      "|    value_loss         | 96.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -84.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.326   |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.177   |\n",
      "|    value_loss         | 3.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 258      |\n",
      "|    ep_rew_mean        | -76.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 647      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.308   |\n",
      "|    explained_variance | 0.0681   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 0.02     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 261      |\n",
      "|    ep_rew_mean        | -76.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 647      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.468   |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.777   |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 264      |\n",
      "|    ep_rew_mean        | -72.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.405   |\n",
      "|    explained_variance | -0.00417 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -2.09    |\n",
      "|    value_loss         | 28       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 264      |\n",
      "|    ep_rew_mean        | -67      |\n",
      "| time/                 |          |\n",
      "|    fps                | 649      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.425   |\n",
      "|    explained_variance | 0.000901 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    value_loss         | 132      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 267      |\n",
      "|    ep_rew_mean        | -65.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 650      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.578   |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.661    |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 267       |\n",
      "|    ep_rew_mean        | -65.9     |\n",
      "| time/                 |           |\n",
      "|    fps                | 648       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.163    |\n",
      "|    explained_variance | -0.248    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -0.000902 |\n",
      "|    value_loss         | 0.000765  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | -59.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | -6.08    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -59.5    |\n",
      "|    value_loss         | 1.01e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | -58      |\n",
      "| time/                 |          |\n",
      "|    fps                | 646      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.594   |\n",
      "|    explained_variance | 0.327    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    value_loss         | 6.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | -52.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.621   |\n",
      "|    explained_variance | 0.745    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.0469  |\n",
      "|    value_loss         | 0.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -52.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.374   |\n",
      "|    explained_variance | 0.469    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.415    |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 275      |\n",
      "|    ep_rew_mean        | -48.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.458    |\n",
      "|    value_loss         | 0.542    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | -49.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 637      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.646   |\n",
      "|    explained_variance | -0.0686  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.419    |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 276       |\n",
      "|    ep_rew_mean        | -47.2     |\n",
      "| time/                 |           |\n",
      "|    fps                | 636       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0849   |\n",
      "|    explained_variance | 0.0157    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -0.000223 |\n",
      "|    value_loss         | 0.000246  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 279      |\n",
      "|    ep_rew_mean        | -44.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 635      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.402   |\n",
      "|    explained_variance | 0.93     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.725    |\n",
      "|    value_loss         | 2.45     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 279      |\n",
      "|    ep_rew_mean        | -40.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 635      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.26    |\n",
      "|    explained_variance | -0.0401  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -0.217   |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -35.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.937   |\n",
      "|    explained_variance | -0.274   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 8.55     |\n",
      "|    value_loss         | 2.3e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | -31.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.227   |\n",
      "|    explained_variance | 0.62     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.0403  |\n",
      "|    value_loss         | 0.712    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 287      |\n",
      "|    ep_rew_mean        | -27.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 637      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0224  |\n",
      "|    explained_variance | 0.85     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.0443  |\n",
      "|    value_loss         | 214      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | -27.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 637      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.309   |\n",
      "|    explained_variance | 0.506    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | -27.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.2     |\n",
      "|    explained_variance | 0.261    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    value_loss         | 13.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | -25.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.299   |\n",
      "|    explained_variance | -0.889   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.418   |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 289      |\n",
      "|    ep_rew_mean        | -23.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.29    |\n",
      "|    explained_variance | 0.000338 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 5.63     |\n",
      "|    value_loss         | 186      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | -22.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.604   |\n",
      "|    explained_variance | 0.477    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.264    |\n",
      "|    value_loss         | 0.869    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 280      |\n",
      "|    ep_rew_mean        | -18.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | 0.0163   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 0.542    |\n",
      "|    value_loss         | 8.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | -19.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.528   |\n",
      "|    explained_variance | 0.01     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 3.71     |\n",
      "|    value_loss         | 110      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 276      |\n",
      "|    ep_rew_mean        | -17      |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.472   |\n",
      "|    explained_variance | 0.745    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.92    |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 279      |\n",
      "|    ep_rew_mean        | -13.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.525   |\n",
      "|    explained_variance | 0.266    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -3.73    |\n",
      "|    value_loss         | 108      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 280      |\n",
      "|    ep_rew_mean        | -13.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.485   |\n",
      "|    explained_variance | -18.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -3.35    |\n",
      "|    value_loss         | 72.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | -13.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.447   |\n",
      "|    explained_variance | 0.0146   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 4.68     |\n",
      "|    value_loss         | 49.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -14.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.574   |\n",
      "|    explained_variance | -0.0461  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -4.15    |\n",
      "|    value_loss         | 43.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -13.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.347   |\n",
      "|    explained_variance | 0.904    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.417   |\n",
      "|    value_loss         | 0.927    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | -11      |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.653   |\n",
      "|    explained_variance | -0.127   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 3.23     |\n",
      "|    value_loss         | 58.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -8.88    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.29    |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 6.5      |\n",
      "|    value_loss         | 298      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 278      |\n",
      "|    ep_rew_mean        | -6.83    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.88    |\n",
      "|    explained_variance | 0.838    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -1.06    |\n",
      "|    value_loss         | 3.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 280      |\n",
      "|    ep_rew_mean        | -10.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.551   |\n",
      "|    explained_variance | 0.254    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.336   |\n",
      "|    value_loss         | 0.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 279      |\n",
      "|    ep_rew_mean        | -5.85    |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0444  |\n",
      "|    explained_variance | 0.364    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    value_loss         | 254      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 275      |\n",
      "|    ep_rew_mean        | -5.52    |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.323   |\n",
      "|    explained_variance | 0.593    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 2.25     |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | -3.98    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.632   |\n",
      "|    explained_variance | 0.752    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 1.04     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 280      |\n",
      "|    ep_rew_mean        | -1.92    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0429  |\n",
      "|    explained_variance | 0.605    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    value_loss         | 145      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | -5.58    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.325   |\n",
      "|    explained_variance | -0.261   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 4.82     |\n",
      "|    value_loss         | 44.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 278      |\n",
      "|    ep_rew_mean        | -1.19    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.492   |\n",
      "|    explained_variance | -0.475   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.499    |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | 0.853    |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.246   |\n",
      "|    explained_variance | -2.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 1.39     |\n",
      "|    value_loss         | 61.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | 1.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.801   |\n",
      "|    explained_variance | 0.932    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -0.724   |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 275      |\n",
      "|    ep_rew_mean        | 7.77     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.372   |\n",
      "|    explained_variance | 0.74     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.203    |\n",
      "|    value_loss         | 5.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 278      |\n",
      "|    ep_rew_mean        | 11.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.684   |\n",
      "|    explained_variance | 0.695    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    value_loss         | 9.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | 12.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.595   |\n",
      "|    explained_variance | -0.00777 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.863    |\n",
      "|    value_loss         | 4.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 276      |\n",
      "|    ep_rew_mean        | 13.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.462   |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.474    |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 278      |\n",
      "|    ep_rew_mean        | 16.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.447   |\n",
      "|    explained_variance | 0.872    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -1.06    |\n",
      "|    value_loss         | 6.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | 14.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.927   |\n",
      "|    explained_variance | -0.0364  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 15       |\n",
      "|    value_loss         | 358      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | 16.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.47    |\n",
      "|    explained_variance | 0.77     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -1.16    |\n",
      "|    value_loss         | 2.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | 15.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.728   |\n",
      "|    explained_variance | 0.974    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 0.381    |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | 19       |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.625   |\n",
      "|    explained_variance | 0.151    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -2.44    |\n",
      "|    value_loss         | 30.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | 20.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.461   |\n",
      "|    explained_variance | 0.893    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 0.536    |\n",
      "|    value_loss         | 5.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | 21.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.425   |\n",
      "|    explained_variance | 0.766    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.427   |\n",
      "|    value_loss         | 0.922    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | 16.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.346   |\n",
      "|    explained_variance | 0.93     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.371   |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 269      |\n",
      "|    ep_rew_mean        | 20.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.449   |\n",
      "|    explained_variance | 0.699    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.189   |\n",
      "|    value_loss         | 2.83     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 267      |\n",
      "|    ep_rew_mean        | 17.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.539   |\n",
      "|    explained_variance | -0.19    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.771    |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 266      |\n",
      "|    ep_rew_mean        | 14.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.514   |\n",
      "|    explained_variance | 0.769    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.756   |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 260      |\n",
      "|    ep_rew_mean        | 11.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.019   |\n",
      "|    explained_variance | 0.586    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 0.00778  |\n",
      "|    value_loss         | 9.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 261      |\n",
      "|    ep_rew_mean        | 9.82     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.663   |\n",
      "|    explained_variance | 0.83     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -1.04    |\n",
      "|    value_loss         | 4.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 262      |\n",
      "|    ep_rew_mean        | 9.74     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.582   |\n",
      "|    explained_variance | 0.685    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -2.68    |\n",
      "|    value_loss         | 56.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 263      |\n",
      "|    ep_rew_mean        | 10.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.258   |\n",
      "|    explained_variance | -0.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 6.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 263      |\n",
      "|    ep_rew_mean        | 11.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.544   |\n",
      "|    explained_variance | 0.765    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -0.476   |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 263      |\n",
      "|    ep_rew_mean        | 12.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.93    |\n",
      "|    explained_variance | 0.84     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -4.46    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 264      |\n",
      "|    ep_rew_mean        | 15.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.493   |\n",
      "|    explained_variance | -0.00203 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 2.35     |\n",
      "|    value_loss         | 23.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 260      |\n",
      "|    ep_rew_mean        | 14.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.465   |\n",
      "|    explained_variance | 0.432    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -2.54    |\n",
      "|    value_loss         | 23.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | 10.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.279   |\n",
      "|    explained_variance | -2.5     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 258      |\n",
      "|    ep_rew_mean        | 12.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.687   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -0.149   |\n",
      "|    value_loss         | 0.0763   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 254      |\n",
      "|    ep_rew_mean        | 8.15     |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.411   |\n",
      "|    explained_variance | 0.694    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -0.697   |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 253      |\n",
      "|    ep_rew_mean        | 10.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.71    |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.869   |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 254      |\n",
      "|    ep_rew_mean        | 14.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.455   |\n",
      "|    explained_variance | 0.768    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.166    |\n",
      "|    value_loss         | 4.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 253      |\n",
      "|    ep_rew_mean        | 19.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.681   |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -0.945   |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 250      |\n",
      "|    ep_rew_mean        | 13       |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.641   |\n",
      "|    explained_variance | 0.671    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.491    |\n",
      "|    value_loss         | 1.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 249      |\n",
      "|    ep_rew_mean        | 12.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.965   |\n",
      "|    explained_variance | 0.88     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -0.358   |\n",
      "|    value_loss         | 0.345    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 247      |\n",
      "|    ep_rew_mean        | 11.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 637      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.217   |\n",
      "|    explained_variance | 0.0113   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.253   |\n",
      "|    value_loss         | 168      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | 4.59     |\n",
      "| time/                 |          |\n",
      "|    fps                | 637      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.096   |\n",
      "|    explained_variance | 0.0924   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 4.98     |\n",
      "|    value_loss         | 173      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 224      |\n",
      "|    ep_rew_mean        | -3.03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00011 |\n",
      "|    explained_variance | -0.456   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 5.95e-05 |\n",
      "|    value_loss         | 59.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 222      |\n",
      "|    ep_rew_mean        | -9.62    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.617   |\n",
      "|    explained_variance | 0.845    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 0.327    |\n",
      "|    value_loss         | 3.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 212      |\n",
      "|    ep_rew_mean        | -17.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.538   |\n",
      "|    explained_variance | -0.498   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.565    |\n",
      "|    value_loss         | 3.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 203       |\n",
      "|    ep_rew_mean        | -22.3     |\n",
      "| time/                 |           |\n",
      "|    fps                | 639       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0107   |\n",
      "|    explained_variance | -6.68e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -0.000217 |\n",
      "|    value_loss         | 0.0379    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 196      |\n",
      "|    ep_rew_mean        | -24.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.581   |\n",
      "|    explained_variance | -10.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.667    |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 191      |\n",
      "|    ep_rew_mean        | -30.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.592   |\n",
      "|    explained_variance | 0.396    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 180      |\n",
      "|    ep_rew_mean        | -37.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.494   |\n",
      "|    explained_variance | 0.759    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -2.44    |\n",
      "|    value_loss         | 3.91     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 173      |\n",
      "|    ep_rew_mean        | -48.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.765   |\n",
      "|    explained_variance | 0.929    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    value_loss         | 0.954    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 167      |\n",
      "|    ep_rew_mean        | -52.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00516 |\n",
      "|    explained_variance | 0.00544  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -0.00068 |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -55.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.569   |\n",
      "|    explained_variance | -5.06    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -2.29    |\n",
      "|    value_loss         | 18.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 157      |\n",
      "|    ep_rew_mean        | -59.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.58    |\n",
      "|    explained_variance | -0.584   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -2.82    |\n",
      "|    value_loss         | 41.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -60.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.801   |\n",
      "|    explained_variance | 0.274    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -2.1     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 140      |\n",
      "|    ep_rew_mean        | -64.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.41    |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    value_loss         | 4.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 132      |\n",
      "|    ep_rew_mean        | -68.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.672   |\n",
      "|    explained_variance | 0.802    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.415    |\n",
      "|    value_loss         | 0.753    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -72      |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.59    |\n",
      "|    explained_variance | 0.496    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -6.42    |\n",
      "|    value_loss         | 7.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 117      |\n",
      "|    ep_rew_mean        | -79.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.583   |\n",
      "|    explained_variance | 0.749    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | -86.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 640      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.571   |\n",
      "|    explained_variance | 0.748    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    value_loss         | 5.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | -91.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.32    |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -0.526   |\n",
      "|    value_loss         | 0.373    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | -93      |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.301   |\n",
      "|    explained_variance | -1.68    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 4        |\n",
      "|    value_loss         | 49.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | -93.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.455   |\n",
      "|    explained_variance | -2.07    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 1.95     |\n",
      "|    value_loss         | 68.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | -88      |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.717   |\n",
      "|    explained_variance | 0.782    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -2.4     |\n",
      "|    value_loss         | 5.92     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | -82.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.622   |\n",
      "|    explained_variance | -3.73    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 3.15     |\n",
      "|    value_loss         | 47.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 110      |\n",
      "|    ep_rew_mean        | -75.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.151   |\n",
      "|    explained_variance | 0.511    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -4.51    |\n",
      "|    value_loss         | 1e+03    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | -72.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0188  |\n",
      "|    explained_variance | -0.0784  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.00503  |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 115      |\n",
      "|    ep_rew_mean        | -61.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.256   |\n",
      "|    explained_variance | 0.239    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -58.6    |\n",
      "|    value_loss         | 5.1e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | -59.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.564   |\n",
      "|    explained_variance | 0.279    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -0.234   |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 120      |\n",
      "|    ep_rew_mean        | -56.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.589   |\n",
      "|    explained_variance | 0.373    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 1.72     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 124      |\n",
      "|    ep_rew_mean        | -50.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.834   |\n",
      "|    explained_variance | 0.983    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.112    |\n",
      "|    value_loss         | 0.174    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -46.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.511   |\n",
      "|    explained_variance | -2.1     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 2.53     |\n",
      "|    value_loss         | 28.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 129      |\n",
      "|    ep_rew_mean        | -46.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.647   |\n",
      "|    explained_variance | -0.966   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.405    |\n",
      "|    value_loss         | 5.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 133       |\n",
      "|    ep_rew_mean        | -43.1     |\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0769   |\n",
      "|    explained_variance | 0.166     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -0.000645 |\n",
      "|    value_loss         | 0.00256   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 136      |\n",
      "|    ep_rew_mean        | -39      |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.798   |\n",
      "|    explained_variance | 0.898    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 140      |\n",
      "|    ep_rew_mean        | -35.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.572   |\n",
      "|    explained_variance | -1.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 3.7      |\n",
      "|    value_loss         | 59.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 141      |\n",
      "|    ep_rew_mean        | -32.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 646      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.703   |\n",
      "|    explained_variance | 0.641    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.494    |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 145      |\n",
      "|    ep_rew_mean        | -28.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.511   |\n",
      "|    explained_variance | -3.36    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    value_loss         | 5.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 145      |\n",
      "|    ep_rew_mean        | -28.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.81    |\n",
      "|    explained_variance | 0.676    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.951   |\n",
      "|    value_loss         | 3.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 154      |\n",
      "|    ep_rew_mean        | -27.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.846   |\n",
      "|    explained_variance | 0.701    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -2.93    |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 154      |\n",
      "|    ep_rew_mean        | -27.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 642      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.913   |\n",
      "|    explained_variance | -0.00621 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 2.06     |\n",
      "|    value_loss         | 4.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -27.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.976   |\n",
      "|    explained_variance | -0.138   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -4.97    |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -27.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.875   |\n",
      "|    explained_variance | -0.305   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    value_loss         | 4.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 172      |\n",
      "|    ep_rew_mean        | -24.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 635      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.793   |\n",
      "|    explained_variance | -0.312   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -5.44    |\n",
      "|    value_loss         | 87.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | -23.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 635      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.765   |\n",
      "|    explained_variance | -0.0909  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 2.55     |\n",
      "|    value_loss         | 22.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -21      |\n",
      "| time/                 |          |\n",
      "|    fps                | 633      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.589   |\n",
      "|    explained_variance | 0.646    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.436   |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 185      |\n",
      "|    ep_rew_mean        | -21.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 633      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.295   |\n",
      "|    explained_variance | 0.381    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -3.94    |\n",
      "|    value_loss         | 52       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 188      |\n",
      "|    ep_rew_mean        | -18.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 633      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.572   |\n",
      "|    explained_variance | 0.906    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 0.0101   |\n",
      "|    value_loss         | 0.3      |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the agent\n",
    "model = A2C('MlpPolicy', env, verbose=1, tensorboard_log=\"./lunar_tensorboard/train_a2c/\")\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=100000)\n",
    "# Save the agent\n",
    "model.save(\"lunar_a2c\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31 22:51:04.402774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 22:51:04.402814: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 22:51:05.255287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-31 22:51:05.255329: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-31 22:51:05.255348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.6.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# analisar os dados de treinamento no TensorBoard\n",
    "#!tensorboard --logdir ./lunar_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained agent - Test\n",
    "model = A2C.load(\"lunar_a2c\", env=env)\n",
    "evaluate_policy(model, model.get_env(), n_eval_episodes=5, render=True)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "mean_reward:-143.54 +/- 28.90\n"
     ]
    }
   ],
   "source": [
    "# Load the trained agent\n",
    "model = DQN.load(\"lunar_dqn\", env=env)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "for i in range(3000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.0003)\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    " \n",
    "env.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained agent\n",
    "model = PPO.load(\"lunar_ppo\", env=env)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "for i in range(3000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.0003)\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "    \n",
    "env.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained agent\n",
    "model = A2C.load(\"lunar_a2c\", env=env)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "for i in range(3000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.0003)\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "    \n",
    "env.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'rl-baselines3-zoo/'\n",
      "/home/marco/rf/rl-baselines3-zoo\n"
     ]
    }
   ],
   "source": [
    "#!git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "%cd rl-baselines3-zoo/\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LunarLander-v2 ==========\n",
      "Seed: 1171006548\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 128),\n",
      "             ('buffer_size', 50000),\n",
      "             ('exploration_final_eps', 0.1),\n",
      "             ('exploration_fraction', 0.12),\n",
      "             ('gamma', 0.99),\n",
      "             ('gradient_steps', -1),\n",
      "             ('learning_rate', 0.00063),\n",
      "             ('learning_starts', 0),\n",
      "             ('n_timesteps', 100000.0),\n",
      "             ('policy', 'MlpPolicy'),\n",
      "             ('policy_kwargs', 'dict(net_arch=[256, 256])'),\n",
      "             ('target_update_interval', 250),\n",
      "             ('train_freq', 4)])\n",
      "Using 1 environments\n",
      "Creating test environment\n",
      "Using cpu device\n",
      "Log path: logs/dqn/LunarLander-v2_3\n",
      "2021-08-31 22:59:38.557647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 22:59:38.557699: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Logging to ../lunar_tensorboard/LunarLander-v2/DQN_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 81       |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 94       |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 324      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.08     |\n",
      "|    n_updates        | 320      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.2     |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 115      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total timesteps  | 690      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 688      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.1     |\n",
      "|    ep_rew_mean      | -143     |\n",
      "|    exploration rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total timesteps  | 1033     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 1032     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88.8     |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 169      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 1420     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 1416     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94       |\n",
      "|    ep_rew_mean      | -145     |\n",
      "|    exploration rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total timesteps  | 1881     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 1880     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -138     |\n",
      "|    exploration rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 168      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total timesteps  | 2393     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.793    |\n",
      "|    n_updates        | 2392     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -137     |\n",
      "|    exploration rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total timesteps  | 2785     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 2784     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -134     |\n",
      "|    exploration rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total timesteps  | 3232     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 3228     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -124     |\n",
      "|    exploration rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 186      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total timesteps  | 3694     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.919    |\n",
      "|    n_updates        | 3692     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -120     |\n",
      "|    exploration rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 190      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total timesteps  | 4081     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 4080     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -117     |\n",
      "|    exploration rate | 0.661    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total timesteps  | 4521     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.36     |\n",
      "|    n_updates        | 4520     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -111     |\n",
      "|    exploration rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total timesteps  | 5027     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 5024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -107     |\n",
      "|    exploration rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total timesteps  | 5441     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 5440     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -103     |\n",
      "|    exploration rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total timesteps  | 5874     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 5872     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -97.3    |\n",
      "|    exploration rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total timesteps  | 6313     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 6312     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | -96.2    |\n",
      "|    exploration rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total timesteps  | 7252     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 7248     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-5.72 +/- 14.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -5.72    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 9996     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 161      |\n",
      "|    ep_rew_mean      | -94.6    |\n",
      "|    exploration rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 164      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total timesteps  | 10930    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 10928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 195      |\n",
      "|    ep_rew_mean      | -90.5    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 163      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total timesteps  | 14073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 14072    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 238      |\n",
      "|    ep_rew_mean      | -87.7    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 172      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 18073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 18072    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-8.87 +/- 15.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -8.87    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 19996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 265      |\n",
      "|    ep_rew_mean      | -85.7    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 157      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total timesteps  | 21235    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 21232    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -83.5    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 167      |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total timesteps  | 25235    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 25232    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 304      |\n",
      "|    ep_rew_mean      | -84.2    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 169      |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total timesteps  | 26719    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 26716    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 324      |\n",
      "|    ep_rew_mean      | -82.3    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 175      |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total timesteps  | 29845    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 29844    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-33.73 +/- 22.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1e+03    |\n",
      "|    mean_reward      | -33.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.667    |\n",
      "|    n_updates        | 29996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 353      |\n",
      "|    ep_rew_mean      | -80      |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 171      |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total timesteps  | 33845    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 33844    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 362      |\n",
      "|    ep_rew_mean      | -79.5    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 175      |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total timesteps  | 36187    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.983    |\n",
      "|    n_updates        | 36184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 372      |\n",
      "|    ep_rew_mean      | -79.3    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total timesteps  | 37485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.835    |\n",
      "|    n_updates        | 37484    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -81.4    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total timesteps  | 38752    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.857    |\n",
      "|    n_updates        | 38748    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=40000, episode_reward=-495.87 +/- 141.05\n",
      "Episode length: 104.80 +/- 37.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | -496     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 0.906    |\n",
      "|    n_updates        | 39996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 391      |\n",
      "|    ep_rew_mean      | -84.1    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total timesteps  | 40110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 40108    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 391      |\n",
      "|    ep_rew_mean      | -88.3    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total timesteps  | 40497    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 40496    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 390      |\n",
      "|    ep_rew_mean      | -97.4    |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total timesteps  | 40905    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 40904    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 389      |\n",
      "|    ep_rew_mean      | -111     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 181      |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total timesteps  | 41279    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.47     |\n",
      "|    n_updates        | 41276    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 389      |\n",
      "|    ep_rew_mean      | -117     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 182      |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total timesteps  | 41652    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 41648    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 388      |\n",
      "|    ep_rew_mean      | -132     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 182      |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total timesteps  | 42039    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.83     |\n",
      "|    n_updates        | 42036    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 388      |\n",
      "|    ep_rew_mean      | -143     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 183      |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total timesteps  | 42471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 42468    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 388      |\n",
      "|    ep_rew_mean      | -153     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 184      |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total timesteps  | 42878    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 42876    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 387      |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 184      |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total timesteps  | 43191    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.95     |\n",
      "|    n_updates        | 43188    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 385      |\n",
      "|    ep_rew_mean      | -190     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total timesteps  | 43574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.76     |\n",
      "|    n_updates        | 43572    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 385      |\n",
      "|    ep_rew_mean      | -205     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total timesteps  | 43946    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 43944    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 384      |\n",
      "|    ep_rew_mean      | -223     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 186      |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total timesteps  | 44260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.18     |\n",
      "|    n_updates        | 44256    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 382      |\n",
      "|    ep_rew_mean      | -243     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 187      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total timesteps  | 44518    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4        |\n",
      "|    n_updates        | 44516    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 376      |\n",
      "|    ep_rew_mean      | -255     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 187      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total timesteps  | 44810    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.47     |\n",
      "|    n_updates        | 44808    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 342      |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 187      |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total timesteps  | 45094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.21     |\n",
      "|    n_updates        | 45092    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 313      |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total timesteps  | 45400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.83     |\n",
      "|    n_updates        | 45396    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 276      |\n",
      "|    ep_rew_mean      | -323     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total timesteps  | 45669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.6      |\n",
      "|    n_updates        | 45668    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 247      |\n",
      "|    ep_rew_mean      | -342     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 45932    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 45928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 210      |\n",
      "|    ep_rew_mean      | -361     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total timesteps  | 46221    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.22     |\n",
      "|    n_updates        | 46220    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | -374     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total timesteps  | 46531    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.7      |\n",
      "|    n_updates        | 46528    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | -395     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 190      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total timesteps  | 46811    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.5     |\n",
      "|    n_updates        | 46808    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | -409     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 190      |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total timesteps  | 47072    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 13       |\n",
      "|    n_updates        | 47068    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | -428     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total timesteps  | 47344    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 47340    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -450     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total timesteps  | 47668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.92     |\n",
      "|    n_updates        | 47664    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.8     |\n",
      "|    ep_rew_mean      | -464     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 192      |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total timesteps  | 47935    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3        |\n",
      "|    n_updates        | 47932    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 81.2     |\n",
      "|    ep_rew_mean      | -482     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 192      |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total timesteps  | 48232    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.32     |\n",
      "|    n_updates        | 48228    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.5     |\n",
      "|    ep_rew_mean      | -498     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 193      |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total timesteps  | 48547    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.79     |\n",
      "|    n_updates        | 48544    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 78.6     |\n",
      "|    ep_rew_mean      | -502     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 193      |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total timesteps  | 48768    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 48764    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77.8     |\n",
      "|    ep_rew_mean      | -507     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 193      |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total timesteps  | 49056    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.7     |\n",
      "|    n_updates        | 49052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77.5     |\n",
      "|    ep_rew_mean      | -523     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 194      |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total timesteps  | 49405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.49     |\n",
      "|    n_updates        | 49404    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 76.3     |\n",
      "|    ep_rew_mean      | -527     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 194      |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total timesteps  | 49665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 15.9     |\n",
      "|    n_updates        | 49664    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.4     |\n",
      "|    ep_rew_mean      | -534     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 194      |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total timesteps  | 49908    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.14     |\n",
      "|    n_updates        | 49904    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-569.13 +/- 160.75\n",
      "Episode length: 63.40 +/- 8.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 63.4     |\n",
      "|    mean_reward      | -569     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.83     |\n",
      "|    n_updates        | 49996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.8     |\n",
      "|    ep_rew_mean      | -540     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 195      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total timesteps  | 50162    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.75     |\n",
      "|    n_updates        | 50160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.5     |\n",
      "|    ep_rew_mean      | -538     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 195      |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total timesteps  | 50442    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.5     |\n",
      "|    n_updates        | 50440    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.3     |\n",
      "|    ep_rew_mean      | -540     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 196      |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total timesteps  | 50704    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 50700    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | -541     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 196      |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total timesteps  | 50929    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 15.9     |\n",
      "|    n_updates        | 50928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | -547     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 196      |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total timesteps  | 51223    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.25     |\n",
      "|    n_updates        | 51220    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | -548     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 197      |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total timesteps  | 51494    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.05     |\n",
      "|    n_updates        | 51492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | -556     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 197      |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total timesteps  | 51761    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.4     |\n",
      "|    n_updates        | 51760    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | -556     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 197      |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total timesteps  | 52045    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.47     |\n",
      "|    n_updates        | 52044    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.4     |\n",
      "|    ep_rew_mean      | -558     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 198      |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total timesteps  | 52342    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 52340    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | -553     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 198      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total timesteps  | 52588    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.53     |\n",
      "|    n_updates        | 52584    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | -550     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 198      |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total timesteps  | 52828    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 52824    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | -553     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 199      |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total timesteps  | 53106    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.8      |\n",
      "|    n_updates        | 53104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | -564     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 199      |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total timesteps  | 53411    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.68     |\n",
      "|    n_updates        | 53408    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | -569     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 200      |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total timesteps  | 53725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 14       |\n",
      "|    n_updates        | 53724    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | -572     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 200      |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total timesteps  | 53967    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.24     |\n",
      "|    n_updates        | 53964    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | -573     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 200      |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total timesteps  | 54239    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 54236    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | -578     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 201      |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total timesteps  | 54555    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.63     |\n",
      "|    n_updates        | 54552    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | -583     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 201      |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total timesteps  | 54838    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.72     |\n",
      "|    n_updates        | 54836    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | -578     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 201      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total timesteps  | 55104    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.29     |\n",
      "|    n_updates        | 55100    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | -565     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 201      |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total timesteps  | 55328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.68     |\n",
      "|    n_updates        | 55324    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | -570     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 201      |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total timesteps  | 55609    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.42     |\n",
      "|    n_updates        | 55608    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | -568     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 202      |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total timesteps  | 55898    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.63     |\n",
      "|    n_updates        | 55896    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | -560     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 202      |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total timesteps  | 56182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.4      |\n",
      "|    n_updates        | 56180    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | -556     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 202      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total timesteps  | 56419    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.07     |\n",
      "|    n_updates        | 56416    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.9     |\n",
      "|    ep_rew_mean      | -557     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 203      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total timesteps  | 56696    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.78     |\n",
      "|    n_updates        | 56692    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.3     |\n",
      "|    ep_rew_mean      | -558     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 203      |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total timesteps  | 56994    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.13     |\n",
      "|    n_updates        | 56992    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | -562     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 203      |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total timesteps  | 57300    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.85     |\n",
      "|    n_updates        | 57296    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | -562     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 204      |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total timesteps  | 57599    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 1.89     |\n",
      "|    n_updates        | 57596    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | -571     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 204      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total timesteps  | 57911    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.36     |\n",
      "|    n_updates        | 57908    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | -568     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 205      |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total timesteps  | 58211    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10       |\n",
      "|    n_updates        | 58208    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70       |\n",
      "|    ep_rew_mean      | -567     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 205      |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total timesteps  | 58491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.97     |\n",
      "|    n_updates        | 58488    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | -562     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 205      |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total timesteps  | 58806    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.7     |\n",
      "|    n_updates        | 58804    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | -566     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 206      |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total timesteps  | 59090    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.98     |\n",
      "|    n_updates        | 59088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.2     |\n",
      "|    ep_rew_mean      | -558     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 206      |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total timesteps  | 59362    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11       |\n",
      "|    n_updates        | 59360    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.9     |\n",
      "|    ep_rew_mean      | -558     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 206      |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total timesteps  | 59675    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.22     |\n",
      "|    n_updates        | 59672    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.2     |\n",
      "|    ep_rew_mean      | -563     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 207      |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total timesteps  | 59952    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.19     |\n",
      "|    n_updates        | 59948    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-623.32 +/- 223.51\n",
      "Episode length: 81.00 +/- 10.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 81       |\n",
      "|    mean_reward      | -623     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.77     |\n",
      "|    n_updates        | 59996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.4     |\n",
      "|    ep_rew_mean      | -555     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 207      |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total timesteps  | 60246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.48     |\n",
      "|    n_updates        | 60244    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.3     |\n",
      "|    ep_rew_mean      | -550     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 207      |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total timesteps  | 60544    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.38     |\n",
      "|    n_updates        | 60540    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.2     |\n",
      "|    ep_rew_mean      | -546     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 207      |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total timesteps  | 60845    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.47     |\n",
      "|    n_updates        | 60844    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72       |\n",
      "|    ep_rew_mean      | -548     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 208      |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total timesteps  | 61165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.08     |\n",
      "|    n_updates        | 61164    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.3     |\n",
      "|    ep_rew_mean      | -551     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 208      |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total timesteps  | 61468    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.98     |\n",
      "|    n_updates        | 61464    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.7     |\n",
      "|    ep_rew_mean      | -541     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 208      |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total timesteps  | 61821    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.96     |\n",
      "|    n_updates        | 61820    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.7     |\n",
      "|    ep_rew_mean      | -534     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 209      |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total timesteps  | 62110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.97     |\n",
      "|    n_updates        | 62108    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.5     |\n",
      "|    ep_rew_mean      | -527     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 209      |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total timesteps  | 62457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.32     |\n",
      "|    n_updates        | 62456    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.8     |\n",
      "|    ep_rew_mean      | -540     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 209      |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total timesteps  | 62807    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.27     |\n",
      "|    n_updates        | 62804    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75.6     |\n",
      "|    ep_rew_mean      | -545     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 210      |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total timesteps  | 63172    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.2      |\n",
      "|    n_updates        | 63168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 76       |\n",
      "|    ep_rew_mean      | -552     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 210      |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total timesteps  | 63502    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.75     |\n",
      "|    n_updates        | 63500    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77       |\n",
      "|    ep_rew_mean      | -552     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 210      |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total timesteps  | 63878    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.63     |\n",
      "|    n_updates        | 63876    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 78.3     |\n",
      "|    ep_rew_mean      | -558     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 210      |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total timesteps  | 64248    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.03     |\n",
      "|    n_updates        | 64244    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.1     |\n",
      "|    ep_rew_mean      | -562     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 211      |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total timesteps  | 64607    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.28     |\n",
      "|    n_updates        | 64604    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.2     |\n",
      "|    ep_rew_mean      | -563     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 211      |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total timesteps  | 65013    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.43     |\n",
      "|    n_updates        | 65012    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.9     |\n",
      "|    ep_rew_mean      | -566     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 211      |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total timesteps  | 65389    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.26     |\n",
      "|    n_updates        | 65388    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 81.8     |\n",
      "|    ep_rew_mean      | -574     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 212      |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total timesteps  | 65784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.91     |\n",
      "|    n_updates        | 65780    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.4     |\n",
      "|    ep_rew_mean      | -569     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 212      |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total timesteps  | 66155    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.06     |\n",
      "|    n_updates        | 66152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 83.3     |\n",
      "|    ep_rew_mean      | -569     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 212      |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total timesteps  | 66543    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.95     |\n",
      "|    n_updates        | 66540    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.3     |\n",
      "|    ep_rew_mean      | -579     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 213      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total timesteps  | 66925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.26     |\n",
      "|    n_updates        | 66924    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 85.1     |\n",
      "|    ep_rew_mean      | -584     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 213      |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total timesteps  | 67315    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 67312    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.6     |\n",
      "|    ep_rew_mean      | -585     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 213      |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total timesteps  | 67746    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.09     |\n",
      "|    n_updates        | 67744    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88       |\n",
      "|    ep_rew_mean      | -592     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 214      |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total timesteps  | 68167    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.13     |\n",
      "|    n_updates        | 68164    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.6     |\n",
      "|    ep_rew_mean      | -598     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 214      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total timesteps  | 68636    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 3.13     |\n",
      "|    n_updates        | 68632    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.6     |\n",
      "|    ep_rew_mean      | -602     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 214      |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total timesteps  | 69111    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.51     |\n",
      "|    n_updates        | 69108    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.7     |\n",
      "|    ep_rew_mean      | -608     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 215      |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total timesteps  | 69515    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.74     |\n",
      "|    n_updates        | 69512    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.3     |\n",
      "|    ep_rew_mean      | -608     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 215      |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total timesteps  | 69973    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.36     |\n",
      "|    n_updates        | 69972    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-614.45 +/- 42.44\n",
      "Episode length: 107.00 +/- 7.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 107      |\n",
      "|    mean_reward      | -614     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.89     |\n",
      "|    n_updates        | 69996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -607     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 215      |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total timesteps  | 70375    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.39     |\n",
      "|    n_updates        | 70372    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.4     |\n",
      "|    ep_rew_mean      | -610     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 215      |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total timesteps  | 70802    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.28     |\n",
      "|    n_updates        | 70800    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.1     |\n",
      "|    ep_rew_mean      | -606     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 216      |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total timesteps  | 71175    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.61     |\n",
      "|    n_updates        | 71172    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -607     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 216      |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total timesteps  | 71560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.94     |\n",
      "|    n_updates        | 71556    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -611     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 216      |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total timesteps  | 71970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5        |\n",
      "|    n_updates        | 71968    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -619     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 216      |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total timesteps  | 72404    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.09     |\n",
      "|    n_updates        | 72400    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -612     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 216      |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total timesteps  | 72738    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.69     |\n",
      "|    n_updates        | 72736    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -613     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 217      |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total timesteps  | 73211    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.03     |\n",
      "|    n_updates        | 73208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -609     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 217      |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total timesteps  | 73576    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.56     |\n",
      "|    n_updates        | 73572    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | -609     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 217      |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total timesteps  | 74013    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.91     |\n",
      "|    n_updates        | 74012    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | -610     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 217      |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total timesteps  | 74453    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.34     |\n",
      "|    n_updates        | 74452    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -606     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 218      |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total timesteps  | 74913    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.35     |\n",
      "|    n_updates        | 74912    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -609     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 218      |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total timesteps  | 75329    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.22     |\n",
      "|    n_updates        | 75328    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -604     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 218      |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total timesteps  | 75735    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.65     |\n",
      "|    n_updates        | 75732    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -597     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 219      |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total timesteps  | 76108    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11       |\n",
      "|    n_updates        | 76104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | -600     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 219      |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total timesteps  | 76579    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.76     |\n",
      "|    n_updates        | 76576    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -592     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 219      |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total timesteps  | 77002    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.28     |\n",
      "|    n_updates        | 77000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | -575     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 219      |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total timesteps  | 77413    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.89     |\n",
      "|    n_updates        | 77412    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -575     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 220      |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total timesteps  | 77996    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.94     |\n",
      "|    n_updates        | 77992    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -564     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 220      |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total timesteps  | 78479    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.86     |\n",
      "|    n_updates        | 78476    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -551     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 220      |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total timesteps  | 78888    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.12     |\n",
      "|    n_updates        | 78884    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -536     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 221      |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total timesteps  | 79510    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.3     |\n",
      "|    n_updates        | 79508    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | -521     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 221      |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total timesteps  | 79985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11       |\n",
      "|    n_updates        | 79984    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-532.55 +/- 224.65\n",
      "Episode length: 111.80 +/- 35.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 112      |\n",
      "|    mean_reward      | -533     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 12.5     |\n",
      "|    n_updates        | 79996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | -520     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 220      |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total timesteps  | 80551    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.7     |\n",
      "|    n_updates        | 80548    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | -508     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 221      |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total timesteps  | 80992    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 13.3     |\n",
      "|    n_updates        | 80988    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | -504     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 221      |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total timesteps  | 81559    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.72     |\n",
      "|    n_updates        | 81556    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | -499     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 221      |\n",
      "|    time_elapsed     | 369      |\n",
      "|    total timesteps  | 81968    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 5.49     |\n",
      "|    n_updates        | 81964    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | -487     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 221      |\n",
      "|    time_elapsed     | 371      |\n",
      "|    total timesteps  | 82421    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 13.6     |\n",
      "|    n_updates        | 82420    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | -472     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 374      |\n",
      "|    total timesteps  | 83230    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 8.74     |\n",
      "|    n_updates        | 83228    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | -457     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 376      |\n",
      "|    total timesteps  | 83733    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.13     |\n",
      "|    n_updates        | 83732    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | -440     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 378      |\n",
      "|    total timesteps  | 84304    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.93     |\n",
      "|    n_updates        | 84300    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | -424     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 379      |\n",
      "|    total timesteps  | 84616    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.93     |\n",
      "|    n_updates        | 84612    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 128      |\n",
      "|    ep_rew_mean      | -408     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 386      |\n",
      "|    total timesteps  | 86032    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11.4     |\n",
      "|    n_updates        | 86028    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | -398     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 392      |\n",
      "|    total timesteps  | 87241    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10       |\n",
      "|    n_updates        | 87240    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | -389     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 395      |\n",
      "|    total timesteps  | 87700    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 13.2     |\n",
      "|    n_updates        | 87696    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | -375     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 396      |\n",
      "|    total timesteps  | 88155    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11.4     |\n",
      "|    n_updates        | 88152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | -368     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 398      |\n",
      "|    total timesteps  | 88494    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 16.3     |\n",
      "|    n_updates        | 88492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | -362     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total timesteps  | 88769    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 6.06     |\n",
      "|    n_updates        | 88768    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | -358     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 401      |\n",
      "|    total timesteps  | 89234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 15.6     |\n",
      "|    n_updates        | 89232    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | -346     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total timesteps  | 89646    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 14.7     |\n",
      "|    n_updates        | 89644    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-446.17 +/- 217.17\n",
      "Episode length: 77.80 +/- 22.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 77.8     |\n",
      "|    mean_reward      | -446     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 18.9     |\n",
      "|    n_updates        | 89996    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | -341     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 404      |\n",
      "|    total timesteps  | 90013    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.7     |\n",
      "|    n_updates        | 90012    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | -344     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 405      |\n",
      "|    total timesteps  | 90393    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 16.3     |\n",
      "|    n_updates        | 90392    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | -347     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 223      |\n",
      "|    time_elapsed     | 406      |\n",
      "|    total timesteps  | 90772    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 90768    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | -345     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 223      |\n",
      "|    time_elapsed     | 407      |\n",
      "|    total timesteps  | 91103    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 14       |\n",
      "|    n_updates        | 91100    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | -345     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 223      |\n",
      "|    time_elapsed     | 409      |\n",
      "|    total timesteps  | 91473    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.7     |\n",
      "|    n_updates        | 91472    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | -346     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 223      |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total timesteps  | 91848    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 14.1     |\n",
      "|    n_updates        | 91844    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | -362     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 223      |\n",
      "|    time_elapsed     | 411      |\n",
      "|    total timesteps  | 92142    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 4.69     |\n",
      "|    n_updates        | 92140    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | -372     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 223      |\n",
      "|    time_elapsed     | 412      |\n",
      "|    total timesteps  | 92411    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 22.1     |\n",
      "|    n_updates        | 92408    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | -367     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 413      |\n",
      "|    total timesteps  | 92691    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.16     |\n",
      "|    n_updates        | 92688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | -377     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 414      |\n",
      "|    total timesteps  | 92948    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 17.1     |\n",
      "|    n_updates        | 92944    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | -381     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 415      |\n",
      "|    total timesteps  | 93201    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 12.8     |\n",
      "|    n_updates        | 93200    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | -381     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 416      |\n",
      "|    total timesteps  | 93479    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 20       |\n",
      "|    n_updates        | 93476    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | -395     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 419      |\n",
      "|    total timesteps  | 94234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.99     |\n",
      "|    n_updates        | 94232    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | -407     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 420      |\n",
      "|    total timesteps  | 94487    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 14       |\n",
      "|    n_updates        | 94484    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | -421     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 421      |\n",
      "|    total timesteps  | 94773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 17.3     |\n",
      "|    n_updates        | 94772    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | -445     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 422      |\n",
      "|    total timesteps  | 95073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 21.8     |\n",
      "|    n_updates        | 95072    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | -461     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 424      |\n",
      "|    total timesteps  | 95357    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 13.4     |\n",
      "|    n_updates        | 95356    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.2     |\n",
      "|    ep_rew_mean      | -476     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 224      |\n",
      "|    time_elapsed     | 425      |\n",
      "|    total timesteps  | 95650    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 14.1     |\n",
      "|    n_updates        | 95648    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.7     |\n",
      "|    ep_rew_mean      | -481     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 426      |\n",
      "|    total timesteps  | 95908    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 12.4     |\n",
      "|    n_updates        | 95904    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.7     |\n",
      "|    ep_rew_mean      | -492     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 427      |\n",
      "|    total timesteps  | 96169    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.85     |\n",
      "|    n_updates        | 96168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 83.1     |\n",
      "|    ep_rew_mean      | -500     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 428      |\n",
      "|    total timesteps  | 96462    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 19       |\n",
      "|    n_updates        | 96460    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.6     |\n",
      "|    ep_rew_mean      | -510     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 429      |\n",
      "|    total timesteps  | 96757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 25.7     |\n",
      "|    n_updates        | 96756    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.4     |\n",
      "|    ep_rew_mean      | -511     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 430      |\n",
      "|    total timesteps  | 97013    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 16.7     |\n",
      "|    n_updates        | 97012    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.5     |\n",
      "|    ep_rew_mean      | -514     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 431      |\n",
      "|    total timesteps  | 97284    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 22.1     |\n",
      "|    n_updates        | 97280    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.1     |\n",
      "|    ep_rew_mean      | -525     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 432      |\n",
      "|    total timesteps  | 97558    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 22.1     |\n",
      "|    n_updates        | 97556    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 78.2     |\n",
      "|    ep_rew_mean      | -528     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 433      |\n",
      "|    total timesteps  | 97837    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 7.85     |\n",
      "|    n_updates        | 97836    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77       |\n",
      "|    ep_rew_mean      | -528     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 434      |\n",
      "|    total timesteps  | 98091    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 9.73     |\n",
      "|    n_updates        | 98088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75.8     |\n",
      "|    ep_rew_mean      | -531     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 435      |\n",
      "|    total timesteps  | 98356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 18.7     |\n",
      "|    n_updates        | 98352    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75.6     |\n",
      "|    ep_rew_mean      | -538     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 225      |\n",
      "|    time_elapsed     | 436      |\n",
      "|    total timesteps  | 98663    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 13.8     |\n",
      "|    n_updates        | 98660    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.4     |\n",
      "|    ep_rew_mean      | -541     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 226      |\n",
      "|    time_elapsed     | 437      |\n",
      "|    total timesteps  | 98912    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.6     |\n",
      "|    n_updates        | 98908    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.2     |\n",
      "|    ep_rew_mean      | -544     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 226      |\n",
      "|    time_elapsed     | 438      |\n",
      "|    total timesteps  | 99169    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 10.7     |\n",
      "|    n_updates        | 99168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.7     |\n",
      "|    ep_rew_mean      | -536     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 226      |\n",
      "|    time_elapsed     | 439      |\n",
      "|    total timesteps  | 99409    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 23       |\n",
      "|    n_updates        | 99408    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.1     |\n",
      "|    ep_rew_mean      | -540     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 226      |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total timesteps  | 99723    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 27.2     |\n",
      "|    n_updates        | 99720    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.1     |\n",
      "|    ep_rew_mean      | -544     |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 226      |\n",
      "|    time_elapsed     | 441      |\n",
      "|    total timesteps  | 99998    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00063  |\n",
      "|    loss             | 22.8     |\n",
      "|    n_updates        | 99996    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-410.10 +/- 45.09\n",
      "Episode length: 58.40 +/- 13.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 58.4     |\n",
      "|    mean_reward      | -410     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total timesteps  | 100000   |\n",
      "----------------------------------\n",
      "Saving to logs/dqn/LunarLander-v2_3\n"
     ]
    }
   ],
   "source": [
    "#RL Baselines3 Zoo - avaliação via TensorBoard DQN\n",
    "!python train.py --algo dqn --env LunarLander-v2 --tensorboard-log ../lunar_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LunarLander-v2 ==========\n",
      "Seed: 904480529\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 64),\n",
      "             ('ent_coef', 0.01),\n",
      "             ('gae_lambda', 0.98),\n",
      "             ('gamma', 0.999),\n",
      "             ('n_envs', 16),\n",
      "             ('n_epochs', 4),\n",
      "             ('n_steps', 1024),\n",
      "             ('n_timesteps', 1000000.0),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 16 environments\n",
      "Creating test environment\n",
      "Using cpu device\n",
      "Log path: logs/ppo/LunarLander-v2_3\n",
      "2021-08-31 23:07:02.641576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 23:07:02.641628: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Logging to ../lunar_tensorboard/LunarLander-v2/PPO_1\n",
      "Eval num_timesteps=10000, episode_reward=-216.18 +/- 158.39\n",
      "Episode length: 122.40 +/- 42.68\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 122      |\n",
      "|    mean_reward     | -216     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 10000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.7     |\n",
      "|    ep_rew_mean     | -177     |\n",
      "| time/              |          |\n",
      "|    fps             | 4263     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-244.35 +/- 23.83\n",
      "Episode length: 67.00 +/- 5.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 67          |\n",
      "|    mean_reward          | -244        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005855074 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.000876   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.01e+03    |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 4.72e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-164.84 +/- 90.62\n",
      "Episode length: 65.80 +/- 4.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 65.8     |\n",
      "|    mean_reward     | -165     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 30000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 93.4     |\n",
      "|    ep_rew_mean     | -153     |\n",
      "| time/              |          |\n",
      "|    fps             | 2817     |\n",
      "|    iterations      | 2        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-218.55 +/- 62.44\n",
      "Episode length: 66.00 +/- 9.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 66          |\n",
      "|    mean_reward          | -219        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007352546 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.0052     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 766         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.8     |\n",
      "|    ep_rew_mean     | -138     |\n",
      "| time/              |          |\n",
      "|    fps             | 2641     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-18.60 +/- 57.81\n",
      "Episode length: 448.80 +/- 450.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 449         |\n",
      "|    mean_reward          | -18.6       |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010247068 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.00261    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 351         |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=60000, episode_reward=61.62 +/- 109.83\n",
      "Episode length: 714.20 +/- 301.43\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 714      |\n",
      "|    mean_reward     | 61.6     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 60000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.9     |\n",
      "|    ep_rew_mean     | -130     |\n",
      "| time/              |          |\n",
      "|    fps             | 2000     |\n",
      "|    iterations      | 4        |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-217.40 +/- 18.99\n",
      "Episode length: 498.60 +/- 60.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 499         |\n",
      "|    mean_reward          | -217        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008871151 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.000688   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 431         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    value_loss           | 884         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-211.19 +/- 14.02\n",
      "Episode length: 454.80 +/- 65.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 455      |\n",
      "|    mean_reward     | -211     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 80000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96.8     |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    fps             | 1931     |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-237.60 +/- 16.77\n",
      "Episode length: 699.00 +/- 95.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 699         |\n",
      "|    mean_reward          | -238        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031208 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -7.05e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 374         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    value_loss           | 679         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.3     |\n",
      "|    ep_rew_mean     | -90.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 1904     |\n",
      "|    iterations      | 6        |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 98304    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-138.93 +/- 146.03\n",
      "Episode length: 702.00 +/- 222.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 702          |\n",
      "|    mean_reward          | -139         |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098974295 |\n",
      "|    clip_fraction        | 0.0787       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 455          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-104.14 +/- 105.61\n",
      "Episode length: 773.00 +/- 289.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 773      |\n",
      "|    mean_reward     | -104     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 110000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -71.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 1719     |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-207.47 +/- 70.88\n",
      "Episode length: 321.40 +/- 19.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 321         |\n",
      "|    mean_reward          | -207        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011911946 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.00019    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 364         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-262.97 +/- 41.05\n",
      "Episode length: 624.20 +/- 290.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 624      |\n",
      "|    mean_reward     | -263     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 130000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 114      |\n",
      "|    ep_rew_mean     | -51.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 1682     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-227.63 +/- 43.63\n",
      "Episode length: 503.60 +/- 158.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 504         |\n",
      "|    mean_reward          | -228        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005060549 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 127      |\n",
      "|    ep_rew_mean     | -44.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 1696     |\n",
      "|    iterations      | 9        |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 147456   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-205.35 +/- 45.52\n",
      "Episode length: 367.40 +/- 78.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 367         |\n",
      "|    mean_reward          | -205        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008418924 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 2.09e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    value_loss           | 408         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-139.83 +/- 34.32\n",
      "Episode length: 293.60 +/- 51.57\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 294      |\n",
      "|    mean_reward     | -140     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 160000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 132      |\n",
      "|    ep_rew_mean     | -30.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 1714     |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-196.63 +/- 78.41\n",
      "Episode length: 674.60 +/- 253.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 675         |\n",
      "|    mean_reward          | -197        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006784834 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 4.3e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 418         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-174.43 +/- 60.66\n",
      "Episode length: 679.20 +/- 224.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 679      |\n",
      "|    mean_reward     | -174     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 180000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 136      |\n",
      "|    ep_rew_mean     | -20.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 1613     |\n",
      "|    iterations      | 11       |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-159.45 +/- 56.76\n",
      "Episode length: 491.60 +/- 274.18\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 492        |\n",
      "|    mean_reward          | -159       |\n",
      "| time/                   |            |\n",
      "|    total timesteps      | 190000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00489858 |\n",
      "|    clip_fraction        | 0.0423     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | -1.19e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 317        |\n",
      "|    n_updates            | 44         |\n",
      "|    policy_gradient_loss | -0.00234   |\n",
      "|    value_loss           | 558        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 159      |\n",
      "|    ep_rew_mean     | -13.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 1605     |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 122      |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-166.21 +/- 31.94\n",
      "Episode length: 379.20 +/- 111.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 379          |\n",
      "|    mean_reward          | -166         |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072809528 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.000221     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 387          |\n",
      "|    n_updates            | 48           |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 561          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-171.48 +/- 53.30\n",
      "Episode length: 519.00 +/- 307.26\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 519      |\n",
      "|    mean_reward     | -171     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 210000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 176      |\n",
      "|    ep_rew_mean     | -17      |\n",
      "| time/              |          |\n",
      "|    fps             | 1569     |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 212992   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-184.48 +/- 70.60\n",
      "Episode length: 515.20 +/- 269.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 515          |\n",
      "|    mean_reward          | -184         |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 220000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057676127 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | -0.0131      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 299          |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 627          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 212      |\n",
      "|    ep_rew_mean     | -15.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 1534     |\n",
      "|    iterations      | 14       |\n",
      "|    time_elapsed    | 149      |\n",
      "|    total_timesteps | 229376   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-152.82 +/- 61.91\n",
      "Episode length: 513.40 +/- 162.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 513        |\n",
      "|    mean_reward          | -153       |\n",
      "| time/                   |            |\n",
      "|    total timesteps      | 230000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00363635 |\n",
      "|    clip_fraction        | 0.0158     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.0247     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 265        |\n",
      "|    n_updates            | 56         |\n",
      "|    policy_gradient_loss | -0.00193   |\n",
      "|    value_loss           | 523        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-190.16 +/- 59.20\n",
      "Episode length: 738.40 +/- 221.77\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 738      |\n",
      "|    mean_reward     | -190     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 240000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 267      |\n",
      "|    ep_rew_mean     | -7.72    |\n",
      "| time/              |          |\n",
      "|    fps             | 1445     |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 245760   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-193.50 +/- 48.32\n",
      "Episode length: 749.60 +/- 254.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 750          |\n",
      "|    mean_reward          | -194         |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 250000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037933933 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.0184       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 259          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 543          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-188.31 +/- 77.16\n",
      "Episode length: 757.40 +/- 189.78\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 757      |\n",
      "|    mean_reward     | -188     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 260000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 346      |\n",
      "|    ep_rew_mean     | 4.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 1350     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 194      |\n",
      "|    total_timesteps | 262144   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-127.12 +/- 42.62\n",
      "Episode length: 786.20 +/- 187.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 786         |\n",
      "|    mean_reward          | -127        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007825481 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.0413      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 236         |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    value_loss           | 511         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 439      |\n",
      "|    ep_rew_mean     | 14.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 17       |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-86.53 +/- 14.34\n",
      "Episode length: 905.80 +/- 188.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 906         |\n",
      "|    mean_reward          | -86.5       |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003317311 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 68          |\n",
      "|    policy_gradient_loss | -0.000904   |\n",
      "|    value_loss           | 402         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-79.07 +/- 15.12\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -79.1    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 290000   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 528      |\n",
      "|    ep_rew_mean     | 25.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 1215     |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 242      |\n",
      "|    total_timesteps | 294912   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-82.59 +/- 10.49\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -82.6        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056283437 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 72           |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-117.58 +/- 27.30\n",
      "Episode length: 966.20 +/- 67.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 966      |\n",
      "|    mean_reward     | -118     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 310000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 596      |\n",
      "|    ep_rew_mean     | 33.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 1135     |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 274      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-59.38 +/- 38.53\n",
      "Episode length: 768.40 +/- 283.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 768         |\n",
      "|    mean_reward          | -59.4       |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008744327 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.0598      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 681      |\n",
      "|    ep_rew_mean     | 43.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 295      |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-29.44 +/- 15.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -29.4        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054368638 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.175        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 202          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-36.88 +/- 16.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -36.9    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 340000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 677      |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 1059     |\n",
      "|    iterations      | 21       |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 344064   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-33.42 +/- 22.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -33.4        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069370223 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 84           |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-47.36 +/- 29.22\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -47.4    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 360000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 718      |\n",
      "|    ep_rew_mean     | 53.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 1009     |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 357      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-49.18 +/- 17.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -49.2       |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006071691 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.5        |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 754      |\n",
      "|    ep_rew_mean     | 64.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 986      |\n",
      "|    iterations      | 23       |\n",
      "|    time_elapsed    | 381      |\n",
      "|    total_timesteps | 376832   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-27.42 +/- 13.50\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -27.4        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 380000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044739046 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 92           |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 91.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-23.29 +/- 9.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -23.3    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 390000   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 765      |\n",
      "|    ep_rew_mean     | 70.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 949      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 414      |\n",
      "|    total_timesteps | 393216   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-19.87 +/- 14.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -19.9        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037435982 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 96           |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 788      |\n",
      "|    ep_rew_mean     | 78.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 932      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 439      |\n",
      "|    total_timesteps | 409600   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-12.80 +/- 21.89\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -12.8        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 410000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043371012 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 83.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-6.43 +/- 16.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -6.43    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 420000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 858      |\n",
      "|    ep_rew_mean     | 89.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 26       |\n",
      "|    time_elapsed    | 469      |\n",
      "|    total_timesteps | 425984   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-31.00 +/- 20.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -31         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005914363 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 104         |\n",
      "|    policy_gradient_loss | -0.000657   |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-6.26 +/- 9.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -6.26    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 440000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 897      |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    fps             | 881      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 502      |\n",
      "|    total_timesteps | 442368   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-28.05 +/- 15.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -28.1        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027431557 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.000116    |\n",
      "|    value_loss           | 72.9         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 888      |\n",
      "|    ep_rew_mean     | 104      |\n",
      "| time/              |          |\n",
      "|    fps             | 869      |\n",
      "|    iterations      | 28       |\n",
      "|    time_elapsed    | 527      |\n",
      "|    total_timesteps | 458752   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=1.34 +/- 18.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 1.34         |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037036415 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 112          |\n",
      "|    policy_gradient_loss | -0.000567    |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=3.06 +/- 26.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.06     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 470000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 879      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 848      |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 559      |\n",
      "|    total_timesteps | 475136   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-8.30 +/- 25.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -8.3         |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044269906 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 116          |\n",
      "|    policy_gradient_loss | -0.000326    |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=490000, episode_reward=-5.62 +/- 20.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -5.62    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 490000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 879      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    fps             | 826      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 594      |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-15.73 +/- 22.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -15.7        |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088286325 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.31         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 80.1         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 881      |\n",
      "|    ep_rew_mean     | 111      |\n",
      "| time/              |          |\n",
      "|    fps             | 816      |\n",
      "|    iterations      | 31       |\n",
      "|    time_elapsed    | 621      |\n",
      "|    total_timesteps | 507904   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-17.68 +/- 22.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -17.7       |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007441753 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-9.07 +/- 17.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -9.07    |\n",
      "| time/              |          |\n",
      "|    total timesteps | 520000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 910      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    fps             | 800      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 655      |\n",
      "|    total_timesteps | 524288   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=31.03 +/- 68.22\n",
      "Episode length: 998.60 +/- 2.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 999         |\n",
      "|    mean_reward          | 31          |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005746209 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.000919   |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=41.64 +/- 65.79\n",
      "Episode length: 997.60 +/- 4.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 998      |\n",
      "|    mean_reward     | 41.6     |\n",
      "| time/              |          |\n",
      "|    total timesteps | 540000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 924      |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    fps             | 781      |\n",
      "|    iterations      | 33       |\n",
      "|    time_elapsed    | 691      |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=40.07 +/- 45.12\n",
      "Episode length: 993.20 +/- 8.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 993         |\n",
      "|    mean_reward          | 40.1        |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004479736 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.964      |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | 0.000124    |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 947      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    fps             | 776      |\n",
      "|    iterations      | 34       |\n",
      "|    time_elapsed    | 717      |\n",
      "|    total_timesteps | 557056   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=125.09 +/- 10.93\n",
      "Episode length: 943.40 +/- 24.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 943          |\n",
      "|    mean_reward          | 125          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 560000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052316287 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.07         |\n",
      "|    n_updates            | 136          |\n",
      "|    policy_gradient_loss | -0.000466    |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=570000, episode_reward=162.03 +/- 27.23\n",
      "Episode length: 928.40 +/- 48.51\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 928      |\n",
      "|    mean_reward     | 162      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 570000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 961      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    fps             | 766      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 748      |\n",
      "|    total_timesteps | 573440   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=144.24 +/- 17.12\n",
      "Episode length: 941.00 +/- 16.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 941          |\n",
      "|    mean_reward          | 144          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 580000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053256215 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.959       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.71         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 982      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    fps             | 755      |\n",
      "|    iterations      | 36       |\n",
      "|    time_elapsed    | 780      |\n",
      "|    total_timesteps | 589824   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=186.21 +/- 15.13\n",
      "Episode length: 777.00 +/- 53.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 777         |\n",
      "|    mean_reward          | 186         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 590000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007914584 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.951      |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.24        |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=600000, episode_reward=186.70 +/- 21.17\n",
      "Episode length: 788.80 +/- 50.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 789      |\n",
      "|    mean_reward     | 187      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 600000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 981      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    fps             | 744      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 814      |\n",
      "|    total_timesteps | 606208   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=172.61 +/- 26.21\n",
      "Episode length: 758.80 +/- 36.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 759          |\n",
      "|    mean_reward          | 173          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 610000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033631236 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.917       |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 148          |\n",
      "|    policy_gradient_loss | -0.000576    |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=166.79 +/- 18.00\n",
      "Episode length: 759.00 +/- 38.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 759      |\n",
      "|    mean_reward     | 167      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 620000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 981      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    fps             | 737      |\n",
      "|    iterations      | 38       |\n",
      "|    time_elapsed    | 844      |\n",
      "|    total_timesteps | 622592   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=212.54 +/- 19.08\n",
      "Episode length: 591.40 +/- 24.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 591          |\n",
      "|    mean_reward          | 213          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 630000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038915435 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.06         |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 968      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    fps             | 736      |\n",
      "|    iterations      | 39       |\n",
      "|    time_elapsed    | 867      |\n",
      "|    total_timesteps | 638976   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=225.30 +/- 19.95\n",
      "Episode length: 530.40 +/- 45.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 530          |\n",
      "|    mean_reward          | 225          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036508946 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.908       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.61         |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.000962    |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=650000, episode_reward=218.64 +/- 21.08\n",
      "Episode length: 526.00 +/- 26.62\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 526      |\n",
      "|    mean_reward     | 219      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 650000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 966      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    fps             | 732      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 895      |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=219.98 +/- 12.03\n",
      "Episode length: 538.60 +/- 19.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 539        |\n",
      "|    mean_reward          | 220        |\n",
      "| time/                   |            |\n",
      "|    total timesteps      | 660000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00449996 |\n",
      "|    clip_fraction        | 0.05       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.924     |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.62       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00114   |\n",
      "|    value_loss           | 30.8       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=216.49 +/- 18.23\n",
      "Episode length: 515.40 +/- 22.10\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 515      |\n",
      "|    mean_reward     | 216      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 670000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 939      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    fps             | 731      |\n",
      "|    iterations      | 41       |\n",
      "|    time_elapsed    | 918      |\n",
      "|    total_timesteps | 671744   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=197.21 +/- 23.77\n",
      "Episode length: 579.00 +/- 33.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 579          |\n",
      "|    mean_reward          | 197          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022803922 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.946       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.3         |\n",
      "|    n_updates            | 164          |\n",
      "|    policy_gradient_loss | -0.000114    |\n",
      "|    value_loss           | 62.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 932      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    fps             | 728      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 944      |\n",
      "|    total_timesteps | 688128   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=218.63 +/- 20.66\n",
      "Episode length: 528.80 +/- 18.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 529          |\n",
      "|    mean_reward          | 219          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 690000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038767841 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.933       |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 168          |\n",
      "|    policy_gradient_loss | 0.000291     |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=222.38 +/- 21.37\n",
      "Episode length: 509.00 +/- 38.85\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 509      |\n",
      "|    mean_reward     | 222      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 700000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 939      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    fps             | 726      |\n",
      "|    iterations      | 43       |\n",
      "|    time_elapsed    | 969      |\n",
      "|    total_timesteps | 704512   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=204.24 +/- 20.19\n",
      "Episode length: 510.60 +/- 22.16\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 511          |\n",
      "|    mean_reward          | 204          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 710000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037346175 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.945       |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.08         |\n",
      "|    n_updates            | 172          |\n",
      "|    policy_gradient_loss | -0.000581    |\n",
      "|    value_loss           | 7.43         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=218.62 +/- 7.36\n",
      "Episode length: 527.00 +/- 17.03\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 527      |\n",
      "|    mean_reward     | 219      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 720000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    fps             | 725      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 994      |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=228.00 +/- 19.95\n",
      "Episode length: 487.00 +/- 45.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 487          |\n",
      "|    mean_reward          | 228          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044721514 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15         |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.000742    |\n",
      "|    value_loss           | 5.28         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    fps             | 727      |\n",
      "|    iterations      | 45       |\n",
      "|    time_elapsed    | 1012     |\n",
      "|    total_timesteps | 737280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=238.57 +/- 21.34\n",
      "Episode length: 441.00 +/- 18.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 441         |\n",
      "|    mean_reward          | 239         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003660657 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.000898   |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=750000, episode_reward=247.65 +/- 8.67\n",
      "Episode length: 449.40 +/- 40.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 449      |\n",
      "|    mean_reward     | 248      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 750000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 951      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    fps             | 730      |\n",
      "|    iterations      | 46       |\n",
      "|    time_elapsed    | 1032     |\n",
      "|    total_timesteps | 753664   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=191.25 +/- 85.82\n",
      "Episode length: 418.60 +/- 66.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 419         |\n",
      "|    mean_reward          | 191         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005041633 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.807      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.43        |\n",
      "|    n_updates            | 184         |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=234.99 +/- 27.30\n",
      "Episode length: 452.20 +/- 36.18\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 452      |\n",
      "|    mean_reward     | 235      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 770000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 927      |\n",
      "|    ep_rew_mean     | 145      |\n",
      "| time/              |          |\n",
      "|    fps             | 733      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 1049     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=244.85 +/- 16.96\n",
      "Episode length: 445.20 +/- 29.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 445         |\n",
      "|    mean_reward          | 245         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 780000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005693066 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 907      |\n",
      "|    ep_rew_mean     | 158      |\n",
      "| time/              |          |\n",
      "|    fps             | 737      |\n",
      "|    iterations      | 48       |\n",
      "|    time_elapsed    | 1066     |\n",
      "|    total_timesteps | 786432   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=252.50 +/- 20.62\n",
      "Episode length: 395.40 +/- 29.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 395          |\n",
      "|    mean_reward          | 253          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 790000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061012683 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.709       |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 192          |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=800000, episode_reward=245.03 +/- 21.12\n",
      "Episode length: 415.60 +/- 15.08\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 416      |\n",
      "|    mean_reward     | 245      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 800000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 792      |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    fps             | 741      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1082     |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=242.47 +/- 15.13\n",
      "Episode length: 389.80 +/- 20.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 390          |\n",
      "|    mean_reward          | 242          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 810000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070058913 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 626      |\n",
      "|    ep_rew_mean     | 208      |\n",
      "| time/              |          |\n",
      "|    fps             | 747      |\n",
      "|    iterations      | 50       |\n",
      "|    time_elapsed    | 1096     |\n",
      "|    total_timesteps | 819200   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=237.20 +/- 14.20\n",
      "Episode length: 386.40 +/- 15.08\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 386          |\n",
      "|    mean_reward          | 237          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 820000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066434024 |\n",
      "|    clip_fraction        | 0.0768       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.742       |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 189          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 325          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=262.54 +/- 11.10\n",
      "Episode length: 369.20 +/- 20.91\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 369      |\n",
      "|    mean_reward     | 263      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 830000   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 443      |\n",
      "|    ep_rew_mean     | 208      |\n",
      "| time/              |          |\n",
      "|    fps             | 752      |\n",
      "|    iterations      | 51       |\n",
      "|    time_elapsed    | 1110     |\n",
      "|    total_timesteps | 835584   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=253.55 +/- 17.92\n",
      "Episode length: 365.60 +/- 26.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 366          |\n",
      "|    mean_reward          | 254          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050316984 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.782       |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 197          |\n",
      "|    n_updates            | 204          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 460          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=249.08 +/- 17.37\n",
      "Episode length: 372.80 +/- 15.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 373      |\n",
      "|    mean_reward     | 249      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 850000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 385      |\n",
      "|    ep_rew_mean     | 209      |\n",
      "| time/              |          |\n",
      "|    fps             | 757      |\n",
      "|    iterations      | 52       |\n",
      "|    time_elapsed    | 1124     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=258.18 +/- 12.79\n",
      "Episode length: 378.80 +/- 15.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 379          |\n",
      "|    mean_reward          | 258          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 860000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030638538 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.732       |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 208          |\n",
      "|    policy_gradient_loss | -0.000734    |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 372      |\n",
      "|    ep_rew_mean     | 223      |\n",
      "| time/              |          |\n",
      "|    fps             | 764      |\n",
      "|    iterations      | 53       |\n",
      "|    time_elapsed    | 1136     |\n",
      "|    total_timesteps | 868352   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=253.39 +/- 26.42\n",
      "Episode length: 374.40 +/- 23.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 374         |\n",
      "|    mean_reward          | 253         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004024604 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 212         |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=880000, episode_reward=244.54 +/- 21.40\n",
      "Episode length: 369.40 +/- 5.35\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 369      |\n",
      "|    mean_reward     | 245      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 880000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 366      |\n",
      "|    ep_rew_mean     | 236      |\n",
      "| time/              |          |\n",
      "|    fps             | 769      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 1149     |\n",
      "|    total_timesteps | 884736   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=258.94 +/- 14.45\n",
      "Episode length: 375.80 +/- 19.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 376          |\n",
      "|    mean_reward          | 259          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 890000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038921067 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.776       |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 216          |\n",
      "|    policy_gradient_loss | 0.000325     |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=245.09 +/- 18.50\n",
      "Episode length: 385.00 +/- 17.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 385      |\n",
      "|    mean_reward     | 245      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 900000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 345      |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    fps             | 775      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 1162     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=238.97 +/- 16.49\n",
      "Episode length: 395.00 +/- 23.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 395          |\n",
      "|    mean_reward          | 239          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 910000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032894714 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.799       |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 487          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 354      |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    fps             | 781      |\n",
      "|    iterations      | 56       |\n",
      "|    time_elapsed    | 1173     |\n",
      "|    total_timesteps | 917504   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=229.68 +/- 55.32\n",
      "Episode length: 481.60 +/- 259.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 482         |\n",
      "|    mean_reward          | 230         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007048574 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.000296   |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=253.78 +/- 17.01\n",
      "Episode length: 369.40 +/- 13.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 369      |\n",
      "|    mean_reward     | 254      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 930000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 372      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    fps             | 785      |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 1188     |\n",
      "|    total_timesteps | 933888   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=253.35 +/- 15.97\n",
      "Episode length: 375.00 +/- 21.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 375          |\n",
      "|    mean_reward          | 253          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 940000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030941502 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.733       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 228          |\n",
      "|    policy_gradient_loss | -0.000275    |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=241.76 +/- 18.69\n",
      "Episode length: 389.20 +/- 10.94\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 389      |\n",
      "|    mean_reward     | 242      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 950000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 379      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    fps             | 791      |\n",
      "|    iterations      | 58       |\n",
      "|    time_elapsed    | 1200     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=218.58 +/- 31.19\n",
      "Episode length: 479.40 +/- 260.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 479         |\n",
      "|    mean_reward          | 219         |\n",
      "| time/                   |             |\n",
      "|    total timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004188375 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.000447   |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 377      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    fps             | 796      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 1213     |\n",
      "|    total_timesteps | 966656   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=264.65 +/- 13.85\n",
      "Episode length: 360.80 +/- 9.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 361          |\n",
      "|    mean_reward          | 265          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 970000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027249046 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.744       |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.05         |\n",
      "|    n_updates            | 236          |\n",
      "|    policy_gradient_loss | -0.000148    |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=980000, episode_reward=256.47 +/- 18.81\n",
      "Episode length: 346.80 +/- 14.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 347      |\n",
      "|    mean_reward     | 256      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 980000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 380      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    fps             | 801      |\n",
      "|    iterations      | 60       |\n",
      "|    time_elapsed    | 1226     |\n",
      "|    total_timesteps | 983040   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=240.35 +/- 14.05\n",
      "Episode length: 362.60 +/- 11.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 363          |\n",
      "|    mean_reward          | 240          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 990000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040460886 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.788       |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.21         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 0.000349     |\n",
      "|    value_loss           | 75.8         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 398      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    fps             | 806      |\n",
      "|    iterations      | 61       |\n",
      "|    time_elapsed    | 1238     |\n",
      "|    total_timesteps | 999424   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=252.92 +/- 19.04\n",
      "Episode length: 353.80 +/- 12.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 354          |\n",
      "|    mean_reward          | 253          |\n",
      "| time/                   |              |\n",
      "|    total timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038897623 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.759       |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 244          |\n",
      "|    policy_gradient_loss | -0.000909    |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=257.13 +/- 13.73\n",
      "Episode length: 356.40 +/- 12.32\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 356      |\n",
      "|    mean_reward     | 257      |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1010000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 388      |\n",
      "|    ep_rew_mean     | 235      |\n",
      "| time/              |          |\n",
      "|    fps             | 810      |\n",
      "|    iterations      | 62       |\n",
      "|    time_elapsed    | 1253     |\n",
      "|    total_timesteps | 1015808  |\n",
      "---------------------------------\n",
      "Saving to logs/ppo/LunarLander-v2_3\n"
     ]
    }
   ],
   "source": [
    "#RL Baselines3 Zoo - avaliação via TensorBoard PPO\n",
    "!python train.py --algo ppo --env LunarLander-v2 --tensorboard-log ../lunar_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LunarLander-v2 ==========\n",
      "Seed: 3085399331\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('ent_coef', 1e-05),\n",
      "             ('gamma', 0.995),\n",
      "             ('learning_rate', 'lin_0.00083'),\n",
      "             ('n_envs', 8),\n",
      "             ('n_steps', 5),\n",
      "             ('n_timesteps', 200000.0),\n",
      "             ('policy', 'MlpPolicy')])\n",
      "Using 8 environments\n",
      "Creating test environment\n",
      "Using cpu device\n",
      "Log path: logs/a2c/LunarLander-v2_3\n",
      "2021-08-31 23:28:01.000763: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 23:28:01.000799: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Logging to ../lunar_tensorboard/LunarLander-v2/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 122      |\n",
      "|    ep_rew_mean        | -250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1950     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | -0.0465  |\n",
      "|    learning_rate      | 0.000814 |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.557    |\n",
      "|    value_loss         | 32.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 146      |\n",
      "|    ep_rew_mean        | -263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2244     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.983   |\n",
      "|    explained_variance | 0.000294 |\n",
      "|    learning_rate      | 0.000797 |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 5.59     |\n",
      "|    value_loss         | 499      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-1007.84 +/- 137.57\n",
      "Episode length: 290.20 +/- 65.89\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 290       |\n",
      "|    mean_reward        | -1.01e+03 |\n",
      "| time/                 |           |\n",
      "|    total timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03     |\n",
      "|    explained_variance | -0.0904   |\n",
      "|    learning_rate      | 0.000789  |\n",
      "|    n_updates          | 249       |\n",
      "|    policy_loss        | -1.4      |\n",
      "|    value_loss         | 698       |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 158      |\n",
      "|    ep_rew_mean        | -222     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1867     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.903   |\n",
      "|    explained_variance | 0.245    |\n",
      "|    learning_rate      | 0.00078  |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 179      |\n",
      "|    ep_rew_mean        | -205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1925     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.927   |\n",
      "|    explained_variance | 0.623    |\n",
      "|    learning_rate      | 0.000764 |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.55    |\n",
      "|    value_loss         | 27.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-2778.56 +/- 279.33\n",
      "Episode length: 779.60 +/- 148.07\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 780       |\n",
      "|    mean_reward        | -2.78e+03 |\n",
      "| time/                 |           |\n",
      "|    total timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.793    |\n",
      "|    explained_variance | 0.226     |\n",
      "|    learning_rate      | 0.000747  |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -2.31     |\n",
      "|    value_loss         | 88.6      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | -197     |\n",
      "| time/              |          |\n",
      "|    fps             | 1361     |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 204      |\n",
      "|    ep_rew_mean        | -173     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1471     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.783   |\n",
      "|    explained_variance | 0.734    |\n",
      "|    learning_rate      | 0.000731 |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -2.1     |\n",
      "|    value_loss         | 80.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 217      |\n",
      "|    ep_rew_mean        | -174     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1479     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.74    |\n",
      "|    explained_variance | 0.673    |\n",
      "|    learning_rate      | 0.000714 |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    value_loss         | 54.8     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-1373.55 +/- 176.57\n",
      "Episode length: 708.00 +/- 87.87\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 708       |\n",
      "|    mean_reward        | -1.37e+03 |\n",
      "| time/                 |           |\n",
      "|    total timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.753    |\n",
      "|    explained_variance | 0.614     |\n",
      "|    learning_rate      | 0.000706  |\n",
      "|    n_updates          | 749       |\n",
      "|    policy_loss        | 0.0577    |\n",
      "|    value_loss         | 83.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -145     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1282     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.802   |\n",
      "|    explained_variance | 0.878    |\n",
      "|    learning_rate      | 0.000697 |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    value_loss         | 47.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 248      |\n",
      "|    ep_rew_mean        | -140     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1284     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.818   |\n",
      "|    explained_variance | 0.937    |\n",
      "|    learning_rate      | 0.000681 |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=40000, episode_reward=-463.21 +/- 124.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -463     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.853   |\n",
      "|    explained_variance | 0.967    |\n",
      "|    learning_rate      | 0.000664 |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.759   |\n",
      "|    value_loss         | 10.2     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 260      |\n",
      "|    ep_rew_mean     | -133     |\n",
      "| time/              |          |\n",
      "|    fps             | 1018     |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 270      |\n",
      "|    ep_rew_mean        | -122     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1056     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.783   |\n",
      "|    explained_variance | 0.457    |\n",
      "|    learning_rate      | 0.000648 |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.641    |\n",
      "|    value_loss         | 41.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1080     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.861   |\n",
      "|    explained_variance | 0.569    |\n",
      "|    learning_rate      | 0.000631 |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -2.48    |\n",
      "|    value_loss         | 109      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-220.55 +/- 261.44\n",
      "Episode length: 859.20 +/- 281.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 859      |\n",
      "|    mean_reward        | -221     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.88    |\n",
      "|    explained_variance | 0.889    |\n",
      "|    learning_rate      | 0.000623 |\n",
      "|    n_updates          | 1249     |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    value_loss         | 20.9     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | -98.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 981      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.898   |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.000614 |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.47    |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | -89.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1002     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.814   |\n",
      "|    explained_variance | -0.0475  |\n",
      "|    learning_rate      | 0.000598 |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -7.34    |\n",
      "|    value_loss         | 961      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-236.26 +/- 120.91\n",
      "Episode length: 883.20 +/- 233.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 883      |\n",
      "|    mean_reward        | -236     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.732   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.000581 |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.494    |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | -74.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 924      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 325      |\n",
      "|    ep_rew_mean        | -60.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 953      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.632   |\n",
      "|    explained_variance | 0.443    |\n",
      "|    learning_rate      | 0.000565 |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.49    |\n",
      "|    value_loss         | 126      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 337      |\n",
      "|    ep_rew_mean        | -54.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 971      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.717   |\n",
      "|    explained_variance | 0.398    |\n",
      "|    learning_rate      | 0.000548 |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2.31     |\n",
      "|    value_loss         | 1.13e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-155.82 +/- 214.06\n",
      "Episode length: 633.60 +/- 143.16\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 634      |\n",
      "|    mean_reward        | -156     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.711   |\n",
      "|    explained_variance | 0.82     |\n",
      "|    learning_rate      | 0.00054  |\n",
      "|    n_updates          | 1749     |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    value_loss         | 50.8     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 351      |\n",
      "|    ep_rew_mean        | -42.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 944      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.739   |\n",
      "|    explained_variance | 0.841    |\n",
      "|    learning_rate      | 0.000531 |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.593   |\n",
      "|    value_loss         | 65.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 356      |\n",
      "|    ep_rew_mean        | -28.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 967      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.596   |\n",
      "|    explained_variance | 0.832    |\n",
      "|    learning_rate      | 0.000515 |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.812   |\n",
      "|    value_loss         | 21.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=80000, episode_reward=-180.12 +/- 57.74\n",
      "Episode length: 949.20 +/- 101.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 949      |\n",
      "|    mean_reward        | -180     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.6     |\n",
      "|    explained_variance | 0.947    |\n",
      "|    learning_rate      | 0.000498 |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.281   |\n",
      "|    value_loss         | 7.15     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 346      |\n",
      "|    ep_rew_mean     | -31.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 356      |\n",
      "|    ep_rew_mean        | -22.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 936      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.72    |\n",
      "|    explained_variance | 0.743    |\n",
      "|    learning_rate      | 0.000482 |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.235    |\n",
      "|    value_loss         | 126      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 337      |\n",
      "|    ep_rew_mean        | -25      |\n",
      "| time/                 |          |\n",
      "|    fps                | 955      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.758   |\n",
      "|    explained_variance | 0.835    |\n",
      "|    learning_rate      | 0.000465 |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    value_loss         | 58.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-141.32 +/- 49.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -141     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.702   |\n",
      "|    explained_variance | 0.969    |\n",
      "|    learning_rate      | 0.000457 |\n",
      "|    n_updates          | 2249     |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 337      |\n",
      "|    ep_rew_mean        | -23.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 896      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.58    |\n",
      "|    explained_variance | 0.843    |\n",
      "|    learning_rate      | 0.000448 |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 1.49     |\n",
      "|    value_loss         | 43.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | -18.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 913      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.697   |\n",
      "|    explained_variance | 0.796    |\n",
      "|    learning_rate      | 0.000432 |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    value_loss         | 46.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-37.21 +/- 168.86\n",
      "Episode length: 858.60 +/- 282.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 859      |\n",
      "|    mean_reward        | -37.2    |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.581   |\n",
      "|    explained_variance | 0.957    |\n",
      "|    learning_rate      | 0.000415 |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 319      |\n",
      "|    ep_rew_mean     | -12.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 867      |\n",
      "|    iterations      | 2500     |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | -3.69    |\n",
      "| time/                 |          |\n",
      "|    fps                | 880      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 104000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.673   |\n",
      "|    explained_variance | 0.816    |\n",
      "|    learning_rate      | 0.000399 |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.797    |\n",
      "|    value_loss         | 49.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 322      |\n",
      "|    ep_rew_mean        | -2.31    |\n",
      "| time/                 |          |\n",
      "|    fps                | 889      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 108000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.574   |\n",
      "|    explained_variance | 0.943    |\n",
      "|    learning_rate      | 0.000382 |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.43     |\n",
      "|    value_loss         | 17       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-26.89 +/- 149.17\n",
      "Episode length: 877.60 +/- 244.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 878      |\n",
      "|    mean_reward        | -26.9    |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.566   |\n",
      "|    explained_variance | 0.0328   |\n",
      "|    learning_rate      | 0.000374 |\n",
      "|    n_updates          | 2749     |\n",
      "|    policy_loss        | -4.52    |\n",
      "|    value_loss         | 1.25e+03 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 338      |\n",
      "|    ep_rew_mean        | 20.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 862      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 112000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | 0.71     |\n",
      "|    learning_rate      | 0.000365 |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -2.27    |\n",
      "|    value_loss         | 40.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 335      |\n",
      "|    ep_rew_mean        | 23.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 877      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 116000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | 0.889    |\n",
      "|    learning_rate      | 0.000349 |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.328    |\n",
      "|    value_loss         | 9.52     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=120000, episode_reward=40.38 +/- 105.05\n",
      "Episode length: 544.00 +/- 374.56\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 544      |\n",
      "|    mean_reward        | 40.4     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.507   |\n",
      "|    explained_variance | 0.439    |\n",
      "|    learning_rate      | 0.000332 |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 5.93     |\n",
      "|    value_loss         | 98.6     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 346      |\n",
      "|    ep_rew_mean     | 36.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 866      |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 353      |\n",
      "|    ep_rew_mean        | 43.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 879      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.643   |\n",
      "|    explained_variance | 0.92     |\n",
      "|    learning_rate      | 0.000316 |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.56    |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 360      |\n",
      "|    ep_rew_mean        | 53       |\n",
      "| time/                 |          |\n",
      "|    fps                | 892      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 128000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.634   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.000299 |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-24.21 +/- 31.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1e+03    |\n",
      "|    mean_reward        | -24.2    |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.523   |\n",
      "|    explained_variance | 0.991    |\n",
      "|    learning_rate      | 0.000291 |\n",
      "|    n_updates          | 3249     |\n",
      "|    policy_loss        | -0.523   |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 358      |\n",
      "|    ep_rew_mean        | 52.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 855      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 132000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.667   |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.000282 |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.474    |\n",
      "|    value_loss         | 23.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 333      |\n",
      "|    ep_rew_mean        | 52.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 868      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 136000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.559   |\n",
      "|    explained_variance | 0.891    |\n",
      "|    learning_rate      | 0.000266 |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -2.05    |\n",
      "|    value_loss         | 24.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=4.89 +/- 17.48\n",
      "Episode length: 844.00 +/- 312.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 844      |\n",
      "|    mean_reward        | 4.89     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 140000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.68    |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.000249 |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.24     |\n",
      "|    value_loss         | 23       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 311      |\n",
      "|    ep_rew_mean     | 54.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 841      |\n",
      "|    iterations      | 3500     |\n",
      "|    time_elapsed    | 166      |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 299      |\n",
      "|    ep_rew_mean        | 49.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 853      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 144000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.599   |\n",
      "|    explained_variance | 0.846    |\n",
      "|    learning_rate      | 0.000233 |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.438    |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | 52       |\n",
      "| time/                 |          |\n",
      "|    fps                | 866      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 148000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.758   |\n",
      "|    explained_variance | 0.641    |\n",
      "|    learning_rate      | 0.000216 |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.61     |\n",
      "|    value_loss         | 57.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-21.40 +/- 20.92\n",
      "Episode length: 832.00 +/- 336.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 832      |\n",
      "|    mean_reward        | -21.4    |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.736   |\n",
      "|    explained_variance | 0.707    |\n",
      "|    learning_rate      | 0.000208 |\n",
      "|    n_updates          | 3749     |\n",
      "|    policy_loss        | 0.452    |\n",
      "|    value_loss         | 41.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | 46.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 844      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 152000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.531   |\n",
      "|    explained_variance | 0.906    |\n",
      "|    learning_rate      | 0.000199 |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.00448 |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 275      |\n",
      "|    ep_rew_mean        | 46.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 856      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 156000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.667   |\n",
      "|    explained_variance | 0.908    |\n",
      "|    learning_rate      | 0.000183 |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -2.48    |\n",
      "|    value_loss         | 22.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-26.80 +/- 31.52\n",
      "Episode length: 534.00 +/- 383.76\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 534      |\n",
      "|    mean_reward        | -26.8    |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.601   |\n",
      "|    explained_variance | 0.842    |\n",
      "|    learning_rate      | 0.000166 |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    value_loss         | 41.7     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 282      |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 847      |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 188      |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | 38.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 856      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 164000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.563   |\n",
      "|    explained_variance | 0.948    |\n",
      "|    learning_rate      | 0.00015  |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.46     |\n",
      "|    value_loss         | 21.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | 36.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 866      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 168000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.76    |\n",
      "|    explained_variance | 0.0445   |\n",
      "|    learning_rate      | 0.000133 |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.00458 |\n",
      "|    value_loss         | 950      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=106.72 +/- 141.41\n",
      "Episode length: 587.40 +/- 343.21\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 587      |\n",
      "|    mean_reward        | 107      |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.571   |\n",
      "|    explained_variance | 0.375    |\n",
      "|    learning_rate      | 0.000125 |\n",
      "|    n_updates          | 4249     |\n",
      "|    policy_loss        | -4.33    |\n",
      "|    value_loss         | 857      |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 300      |\n",
      "|    ep_rew_mean        | 42.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 857      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 172000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.728   |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.000116 |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    value_loss         | 7.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | 47.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 867      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 176000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.723   |\n",
      "|    explained_variance | 0.911    |\n",
      "|    learning_rate      | 9.98e-05 |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    value_loss         | 31.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=19.64 +/- 102.43\n",
      "Episode length: 885.60 +/- 228.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 886      |\n",
      "|    mean_reward        | 19.6     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.581   |\n",
      "|    explained_variance | 0.983    |\n",
      "|    learning_rate      | 8.32e-05 |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    value_loss         | 8.01     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 50.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 845      |\n",
      "|    iterations      | 4500     |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | 55.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 855      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 184000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.472   |\n",
      "|    explained_variance | 0.59     |\n",
      "|    learning_rate      | 6.66e-05 |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.978    |\n",
      "|    value_loss         | 63.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 308      |\n",
      "|    ep_rew_mean        | 64.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 863      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 188000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | 0.937    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.035    |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=93.15 +/- 94.31\n",
      "Episode length: 756.20 +/- 324.81\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 756      |\n",
      "|    mean_reward        | 93.1     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.606   |\n",
      "|    explained_variance | 0.922    |\n",
      "|    learning_rate      | 4.17e-05 |\n",
      "|    n_updates          | 4749     |\n",
      "|    policy_loss        | -2.76    |\n",
      "|    value_loss         | 38.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 69.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 849      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.634   |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 3.34e-05 |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.843   |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 312      |\n",
      "|    ep_rew_mean        | 71.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 858      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 196000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.693   |\n",
      "|    explained_variance | 0.449    |\n",
      "|    learning_rate      | 1.68e-05 |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -3.95    |\n",
      "|    value_loss         | 384      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=14.37 +/- 87.20\n",
      "Episode length: 928.00 +/- 144.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 928      |\n",
      "|    mean_reward        | 14.4     |\n",
      "| time/                 |          |\n",
      "|    total timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.764   |\n",
      "|    explained_variance | 0.909    |\n",
      "|    learning_rate      | 1.66e-07 |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -2.55    |\n",
      "|    value_loss         | 28.8     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 314      |\n",
      "|    ep_rew_mean     | 73.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 843      |\n",
      "|    iterations      | 5000     |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "Saving to logs/a2c/LunarLander-v2_3\n"
     ]
    }
   ],
   "source": [
    "#RL Baselines3 Zoo - avaliação via TensorBoard A2C\n",
    "!python train.py --algo a2c --env LunarLander-v2 --tensorboard-log ../lunar_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisar os dados de treinamento e do RL Baselines3 Zoo no TensorBoard\n",
    "#!tensorboard --logdir ./lunar_tensorboard/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
